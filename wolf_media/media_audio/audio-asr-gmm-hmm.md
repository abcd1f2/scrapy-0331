## media-audio asr gmm hmm
- **概述：**
>
>

- **声学模型：**
>       声学模型的目的是将经MFCC提取的所有帧的特征向量转化为有序的音素输出
>
>       现在大多数识别都采用三音素模型
>       聚类算法来对所有的上下文相关的三音素做聚类，得到绑定状态聚类的一个集合
>
>       GMM：
>           GMM主要是为了得到HMM求解过程的发射概率
>       HMM：
>           就是根据各个概率得到最优的音素
>           聚类算法来对所有的上下文相关的三音素做聚类，得到绑定状态聚类的一个集合
>           现在大多数识别都采用三音素模型，为了压缩建模单元数量，状态绑定的技术被大量使用，它使得发音类似的状态用一个模型表表示，从而减少了参数量。！！！
>               状态绑定的技术可以使用专家手工编撰的规则，也可以使用数据驱动的方式。
>
>

- **识别的三步：**
>       1、第一步，把帧识别成状态（gmm）
>       2、第二步，把状态组合成音素（hmm）
>       3、第三步，把音素组合成单词（hmm）
>
>

- **hmm：**
>       前向概率、后向概率：
>           前向概率：
>               2、中括号意思就是当前层的所有N个隐状态与下一层的第i个状态的连接，里面的 α 是到时刻t部分观测序列为，
>                   且在 t 时刻处于状态 j 的概率（前向计算给出，第一层用的是过程①），a是 t 时刻第 j 个状态到 t+1 时刻第 i 个状态的转移情况（转移矩阵给出）；
>                   中括号外面乘以的b是当前状态下，对应观测情况发生的概率，比如当前是晴天，那么晴天对应海藻湿润的概率是什么呢?就是b，由混淆矩阵给出。
>               3、其实就是求解在时刻t，所有状态的概率求和
>           后向概率：
>               2、对于t=T-1,T-2,...1递推计算，时刻 t 状态为条件下时刻t+1之后的观测序列为的后向概率，
>                   其实就是第t+1 时刻的N个状态到t 时刻状态的转移概率乘以t+1时刻每个隐状态对应的观察情况为o(t+1)的概率，再乘以状态j之后的观测序列的后向概率
>               3、计算一种加和，但是与前向算法的加和还不一样，它的含义是与步骤②一样的，只不过初始概率 π 代替了转移概率a
>
>

- **gmm和hmm参数估计：**
>       gmm参数估计：
>           E（estimate）-step: 根据当前参数 (means, variances, mixing parameters)估计P(j|x)
>           M（maximization）-step: 根据当前P(j|x) 计算GMM参数
>
>       HMM参数估计：
>           E（estimate）-step: 给定observation序列，估计时刻t处于状态sj的概率γt(j)
>           M（maximization）-step: 根据γt(j)重新估计HMM参数aij
>
>       gmmhmm结合：
>           假设状态->observation服从单核高斯概率分布
>
>       gmm-hmm结合识别：
>           一是把当前frame的特征识别为这个state的概率(也就是GMM中的mean vector 和covariance matrix )
>           二是上个state转化为这个state的概率也就是状态转移概率Transition probabilities。
>
>
>

- **一段语音是怎么切割音素？**
>       如'我'的拼音是wo，我们按声韵母分开是：w o？
>       答案：
>           如果要训练w和o的分界点在哪我们不知道，所以HMM模型的训练就是问题。
>           这里使用EM算法，开始随机对语音分帧，例如平均分割语音，使用EM算法和前向后向算法
>           E步是求出每一帧位于哪个音素，M步是对于每个音素，找到它对应的所有帧，从这些帧的特征中估计音素模型的参数。
>           对齐之后就可以对每个状态进行GMM训练，之后循环E步M步。其中E步只要判断相邻音素的那一帧属于左边音素还是右边音素就可以了。
>
>

- **孤立词识别中的GMM-HMM和连续词识别中的GMM-HMM有什么不一样？**
>       孤立词识别中每个词都有自己的GMM-HMM，也就是说虽然有的词包括有相同的音素，但是数据不共享。
>       大词汇量的训练中，是对音素建立GMM-HMM模型，所以数据共享。
>
>

- **待续：**
>       参考：https://blog.csdn.net/abcjennifer/article/details/27346787   GMM-HMM语音识别模型 原理篇
>           https://blog.csdn.net/wbgxx333/article/details/18516053     语音识别系统原理介绍---从gmm-hmm到dnn-hmm
>           https://www.xuebuyuan.com/2100302.html  语音识别系统原理介绍—-gmm-hmm
>           https://blog.csdn.net/wbgxx333/article/details/10020449     语音信号处理之（四）梅尔频率倒谱系数（MFCC）
>           https://mp.weixin.qq.com/s/Sn4RPdghzzQhQc-r4z8Iuw   Kaldi单音素GMM学习笔记
>
>           https://www.jianshu.com/p/a431d994e76b  hmm计算过程
>
>
>
>
>
>
>
>
>
>
>
