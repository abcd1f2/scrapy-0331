## media-audio ctc（Connectionist temporal classification）
- **概述：**
>       目前主流的语音识别都大致分为特征提取，声学模型，语音模型
>       目前结合神经网络的端到端的声学模型训练方法主要CTC和基于Attention两种
>
>
>
>

- **CTC：**
>       CTC是一种损失函数，它用来衡量输入的序列数据经过神经网络之后，和真实的输出相差有多少。
>
>       传统的语音识别的声学模型训练，对于每一帧的数据，需要知道对应的label才能进行有效的训练，在训练数据之前需要做语音对齐的预处理。
>           而语音对齐的过程本身就需要进行反复多次的迭代，来确保对齐更准确，这本身就是一个比较耗时的工作。
>
>       CTC模型：
>           与传统的声学模型训练相比，采用CTC作为损失函数的声学模型训练，是一种完全端到端的声学模型训练，不需要预先对数据做对齐，只需要一个输入序列和一个输出序列即可以训练。
>               这样就不需要对数据对齐和一一标注，并且CTC直接输出序列预测的概率，不需要外部的后处理。
>           既然CTC的方法是关心一个输入序列到一个输出序列的结果，那么它只会关心预测输出的序列是否和真实的序列是否接近（相同），
>               而不会关心预测输出序列中每个结果在时间点上是否和输入的序列正好对齐
>
>           CTC引入了blank（该帧没有预测值），每个预测的分类对应的一整段语音中的一个spike（尖峰），其他不是尖峰的位置认为是blank。
>               对于一段语音，CTC最后的输出是spike（尖峰）的序列，并不关心每一个音素持续了多长时间。
>               进过CTC预测的序列结果在时间上可能会稍微延迟于真实发音对应的时间点，其他时间点都会被标记会blank。
>
>           神经网络+CTC应用：
>               神经网络+CTC的结构除了可以应用到语音识别的声学模型训练上以外，也可以用到任何一个输入序列到一个输出序列的训练上（要求：输入序列的长度大于输出序列）
>               比如，OCR识别也可以采用RNN+CTC的模型来做
>                   将包含文字的图片每一列的数据作为一个序列输入给RNN+CTC模型，输出是对应的汉字，因为要好多列才组成一个汉字，所以输入的序列的长度远大于输出序列的长度。
>                   而且这种实现方式的OCR识别，也不需要事先准确的检测到文字的位置，只要这个序列中包含这些文字就好了。
>

- **RNN+CTC模型的训练：**
>       在语音识别中，RNN+CTC模型的训练详细过程，到底RNN+CTC是如何不用事先对齐数据来训练序列数据的。
>       CTC是一种损失函数，它用来衡量输入的序列数据经过神经网络之后，和真实的输出相差有多少。
>
>
>
>
>
>
>

- **待续：**
>       参考：https://www.cnblogs.com/qcloud1001/p/9041218.html    语音识别中的CTC算法的基本原理解释
>           https://x-algo.cn/index.php/2017/05/31/2345/    CTC原理
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
