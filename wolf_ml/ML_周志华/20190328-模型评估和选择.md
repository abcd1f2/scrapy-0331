## 周志华-机器学习 - 模型评估和选择
- **概述：**
>       评估方法：
>           自助法
>               优点：数据较小、难以有效划分训练和测试集时很有用
>               缺点：改变了初始数据集的分布，会引入估计偏差
>           留出法和交叉验证：
>               在初始数据足够时，留出法和交叉验证法更常用
>
>

- **调参：**
>       调参：
>           训练集、验证集、测试集
>
>

- **性能度量：**
>       性能度量：
>           均分误差等
>
>           精确率、召回率、F1
>               (P-R曲线)
>               在不同应用中，查全率和查准率的重视程度不同，如推荐系统中，为了尽量不打扰用户，查准率更重要，在逃犯信息检索中，查全率更重要
>
>           ROC和AUC：
>               很多预测结果为一个概率值，如何选择概率划分阈值，如果更重视查准率，则可旋转排序中靠前的位置进行阈值划分截断；如果更重视查全率，则可选择更靠后的位置进行划分截断。
>               ROC曲线是用来研究泛化性能的有力工具
>
>           均等代价和非均等代价：
>               在非均等代价下，ROC曲线不能直接反映出学习器的期望总体代价，而代价曲线则可以达到该目的。
>

- **比较检验：**
>       若在测试集上观察到学习器A比B好，则A的泛化性能是否在统计意义上优于B，以及这个结论的把握有多大。
>       假设检验
>       交叉验证t检验
>       McNemar检验
>       Friedman与Nemenyi检验
>

- **偏差与方差**
>       偏差-方差分解是解释学习算法泛化性能的一种重要工具，偏差-方差分解试图对学习算法的期望泛化错误率进行拆解。
>       返回误差可以分解为偏差、方差和噪声之和
>           偏差：度量了算法的期望预测与真实值的偏离程度
>           方差：刻画了数据扰动所造成的影响
>           噪声：表达了当前任务上任何算法所能达到的期望泛化误差的下界，即刻画了学习问题本身的难度
>       偏差-方差分解说明
>           泛化性能是由学习算法的能力、数据的充分性以及任务本身的难度所共同决定的
>       偏差-方差窘境：
>           偏差和方差是由冲突的，如下图，
> ![avatar](https://github.com/nwaiting/wolf-ai/blob/master/wolf_others/ml_pic/ml_train_error_vs_var.png)
>
>
>
>
>
>
>

- **待续：**
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
