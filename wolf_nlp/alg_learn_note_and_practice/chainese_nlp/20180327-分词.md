### NLP汉语自然语言处理原理与实践-2-词汇与分词技术
- **概述：**
> ICTCLAS商业版成为精度最高、速度最快的中文分词系统，
> ICTCLAS算法思想来源于HMM
>
> 相关参考：
>       吕震宇的BLOG http://www.cnblogs.com/zhenyulu/category/85598.html
>       ictclas开源(1.0)版本：https://github.com/nwaiting/ictclas
>
>**流程：**
> HanLP分词流程：
>       0、预处理
>           在进行原子切分前，先进行文本的预处理，预处理过程为根据分隔符将文本分割成单个句子
>       实例："他说的确实在理"
>       1、先粗分 原子切分 一元词网
>           http://www.hankcs.com/nlp/segment/the-word-graph-is-generated.html
>           https://blog.csdn.net/sinboy/article/details/663123 (cpp解析)
>           先进行字符级切分，句子切分为单个utf8编码的字符数组，单个中文字符、单个英文字符、其他字符等
>
>           查询核心词典，将原子切分的结果与词典中的词进行最大匹配,包括词形、词性、词频等信息形成**一元词网**
>           保存到二维数组中，之后查询每个字符的CharType，生成每个字符的原子词类型，然后对汉字类型不做处理,
>           比如合并浮点类型数字("3,.,1,4"合并为3.14)，合并数字("1,0,0"合并为100)，合并ascii字符
>           ("i,p,h,o,n,e"合并为iphone)，这个过程称为原子切分
>
>           原子切分："始##始/他/说/的/确/实/在/理/末##末"
>         然后一元切分 就是把原子之间所有可能的组合都先找出来
>           一元切分："始##始/他/说/的/的确/确/确实/实/实在/在/在理/末##末"
>         HanLP加载核心词典过程：
>            1、使用red-back-tree将核心词典加载进来，然后构造一棵双数组trie树即字典树，引入trie树的
>               原因是hash在大规模下的空间利用率较低(双数组trie树Double-Array trie就是
>               将trie用两个整型数组来表示，仅用两个线性数组来表示trie树，该结构有效结合了
>               数字搜索树检索时间高效的特点和链式表示的trie空间结构紧凑的特点)
>            注：双数组trie树拥有trie树的所有优点，还克服了trie树浪费空间的不足，应用范围比较广泛
>               双数组trie的缺点是每个状态的更新依赖其他状态，所以更新的灵活性差，适合加载后不用更新的更新的查询操作
>               如：词法分析器、图书检索、拼写检查、单词过滤器、自然语言中的字典构建等
>
>       2、二元切分 二元词图
>            用一元查询结果查询二元模型词典，与二元词典进行最大匹配，匹配结果为一个Graph，形成一个词图
>            找出词之间的两两组合和权重计算(此处有一个平滑处理)
>            找出两两组合：
>            权重计算：根据贝叶斯公式，以及一阶HMM展开式，为了计算方便，常用负数对数来计算
>
>       3、最短路径 NShort最短路径
>           N最短路径就是最短路径和最大路径的折中，保留前N个最优路径(Dijkstra算法)
>
>       4、应用规则
>           未登录词识别，使用隐马模型，会用到人名(Viterbi)、地名(Viterbi)、机构名(Dijkstra)等词典模型
>           HanLP命名实体识别使用了HMM和Viterbi算法
>
>       5、优化细分逻辑
>           将命名实体识别后的分词结果加入到词图，对词图再次进行分词(Dijkstra)
>
>       6、词性标注
>           使用词性标注模型和Viterbi算法，对分词结果进行词性标注
>
>       7、后处理，分词结果
>           将最短路径转换为分词结果
>
>








































a
