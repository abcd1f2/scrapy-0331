### 七月在线机器学习 -- regression
- **概述：**：
>       降维属于无监督学习
>       loss function：
>           平方损失
>           log损失
>           hirge 损失
>           指数损失
>           交叉熵损失
>       线性回归：
>           loss function：平方损失
>           做分类抵抗噪声能力差
>
>       梯度下降：
>           优化算法
>
>       学习率：
>           也叫超参数（影响是否收敛的重要条件，如果不收敛，需要查看是否学习率设置合适）
>           设置很大时，会在极小值附近震荡
>
>       欠拟合或过拟合：
>           k折交叉验证
>
>       正则化：
>           1、控制参数幅度，不让模型失控
>           2、限制参数搜索空间
>           L1正则化：|θ|
>           L2正则化：θ^2（可导）
>           λ∑θ^2 正则化项
>           λ：超参数，正则化程度
>           添加正则化的损失函数，不让参数θ的平方过大，限制参数的搜索空间
>
>

- **损失函数：**
>       损失函数要为非凸函数，这样就能找到全局最优解，否则可能只能找到局部最优解，达不到全局最优
>       cost function 和 loss function
>       损失函数和代价函数
>
>


- **逻辑回归：**
>       sigmoid函数 压缩函数
>       判定边界
>       损失函数：
>           用平方损失的话，是一个非凸函数
>           log损失函数（凸函数）
>           正则化项（L2正则化） 对复杂的逻辑回归中使用，限制θ的范围
>
>
>
>
>
>
>
>
>
>
>
>

- **待续：**
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
