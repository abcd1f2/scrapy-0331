### 七月在线机器学习 -- 最大熵模型
- **概述：**
>       熵：不确定性的描述
>       条件熵(joint entropy) H(P(y|x))
>           H(X|Y) = H(X,Y) - H(Y)
>       联合熵（condition entropy） H(x,y)
>       互信息（mutual infomation）
>           I(X:Y) = H(X) - H(X|Y) = H(X) + H(Y) - H(X,Y)
>       相对熵（KL divergence）：
>           学到的分布好坏的指标
>           衡量两个概率分布的区别大小
>       最大熵原理：
>           在学习概率模型的时候，在所有可能的概率模型中，熵最大的模型是最好的模型
>           两个约束条件：
>               1、学习概率和经验概率相同
>               2、在满足1条件下的熵最大
>
>       LR、max entropy和softmax区别：
>           最后的形式都类似于softmax
>
>

- **EM：**
>       EM：expectation maxmization 期望最大化
>       混合模型（mixture models）：
>           mixture of Gaussians：
>
>
>

- **优化算法：**
>       最大熵模型里面的优化算法GIS和IIS有什么区别？
>       GIS(generalized iterative scaling)是Darroch 和 Ratcliff 在七十年代提出的通用迭代算法。大致步骤如下：
>           1） 假定第零次迭代的初始模型为等概率的均匀分布。
>           2）用第 N 次迭代的模型来估算每种信息特征在训练数据中的分布，如果超过了实际的，就把相应的模型参数变小；否则，将它们变大。即对每个i调整λi:λi+=logE˜p(fi)/Ei
>           3）重复步骤 2 直到收敛。
>       GIS算法缺点：
>           GIS算法很尴尬的地方在于每次迭代的时间都很长，且需要迭代很多次才能收敛，不太稳定，有时候在 64 位计算机上都会出现溢出。
>
>       IIS改进迭代算法：
>           八十年代，Della Pietra 在 IBM 对 GIS 算法进行了两方面的改进，提出了改进迭代算法 IIS(improved iterative scaling)，
>           这使得最大熵模型的训练时间相对GIS缩短了一到两个数量级(实际上是更少的迭代步数，但是每步时间会长一点)。这样最大熵模型才有可能在工业界用起来。
>
>       IIS与GIS最大的区别在于修正λ的方法：
>           1）对所有 i 初始化 λi= 0
>           2）对所有 i
>               a、求解方程∑x,y˜p(x)p(y|x)fi(x,y)exp(∆λif#(x,y)) = ˜p(fi)的解∆i，其中
>                   f#(x,y) = ∑fi(x,y)
>               b、根据∆λi更新λi的值: λi ← λi + ∆λi
>           3）重复步骤 2 直到收敛。
>
>
>
>
>
>
>
>
>
>
>
>

- **待续：**
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
