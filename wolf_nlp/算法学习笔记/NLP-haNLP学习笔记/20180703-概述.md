### NLP-HanLP -- 概述
- **概述**：
>       HaNLP中的数据分为词典和模型，其中词典是词法分析必需的，模型是句法分析必需的
>
>       包含多种分词算法：
>           **标准分词**
>               标注分词是最常用的分词器，基于hmm-viterbi，具有中国人名识别和音译人名识别，是一种静态分词器，分词结果包含词性
>               词图的生成： http://www.hankcs.com/nlp/segment/the-word-graph-is-generated.html
>           **NLP分词**
>               执行全部命名实体识别和词性标注
>               速度比标准分词慢
>
>           **索引分词**
>               面向搜索引擎的分词器，能够对长词全切分
>
>           **N最短路径分词**
>               N最短分词器比最短路分词器慢，效果稍微好一些，对命名实体识别能力更强
>
>           **CRF分词**
>               CRF对新词有很好的识别能力，但是无法利用自定义词典
>
>           **极速词典分词**
>               极速分词是词典最长分词，速度极其快，精度一般
>
>
>       命名实体识别算法：
>           **中国人名识别：**
>               基于hmm-viterbi算法
>               http://www.hankcs.com/nlp/chinese-name-recognition-in-actual-hmm-viterbi-role-labeling.html
>
>           **音译人名识别：**
>               基于层叠隐马模型
>               http://www.hankcs.com/nlp/name-transliteration-cascaded-hidden-markov-model-and-japanese-personal-names-recognition.html
>
>           **日本人名识别：**
>               基于层叠隐马模型
>               http://www.hankcs.com/nlp/name-transliteration-cascaded-hidden-markov-model-and-japanese-personal-names-recognition.html
>
>           **地名识别：**
>               hmm-viterbi地名识别
>               http://www.hankcs.com/nlp/ner/place-names-to-identify-actual-hmm-viterbi-role-labeling.html
>
>           **机构名识别：**
>               hmm-viterbi机构名识别
>               http://www.hankcs.com/nlp/ner/place-name-recognition-model-of-the-stacked-hmm-viterbi-role-labeling.html
>
>       文本算法：
>           **关键词提取：**
>               TextRank提取关键词
>               http://www.hankcs.com/nlp/textrank-algorithm-to-extract-the-keywords-java-implementation.html
>
>           **自动摘要：**
>               TextRank自动摘要
>               http://www.hankcs.com/nlp/textrank-algorithm-java-implementation-of-automatic-abstract.html
>
>           **短语提取：**
>               基于互信息和左右信息熵的短语提取
>               http://www.hankcs.com/nlp/extraction-and-identification-of-mutual-information-about-the-phrase-based-on-information-entropy.html
>
>           **音字转换、简繁转换：**
>               ac算法升级
>               http://www.hankcs.com/nlp/java-chinese-characters-to-pinyin-and-simplified-conversion-realization.html#h2-17
>
>           **文本推荐：**
>               搜索引擎的联想推荐
>
>           **依存句法解析：**
>               基于神经网络、最大熵、crf的依存句法解析
>               http://www.hankcs.com/nlp/parsing/crf-sequence-annotation-chinese-dependency-parser-implementation-based-on-java.html
>

- **词典介绍：**
>       人名识别：
>           data/dictionary/person
>       地名识别：
>           data/dictionary/place
>       组织机构名：
>           data/dictionary/organization
>
>       #核心词典路径
>       CoreDictionaryPath=data/dictionary/CoreNatureDictionary.txt
>       #2元语法词典路径
>       BiGramDictionaryPath=data/dictionary/CoreNatureDictionary.ngram.txt
>       #停用词词典路径
>       CoreStopWordDictionaryPath=data/dictionary/stopwords.txt
>       #同义词词典路径
>       CoreSynonymDictionaryDictionaryPath=data/dictionary/synonym/CoreSynonym.txt
>       #人名词典路径
>       PersonDictionaryPath=data/dictionary/person/nr.txt
>       #人名词典转移矩阵路径
>       PersonDictionaryTrPath=data/dictionary/person/nr.tr.txt
>       日本人名词典
>       data/dictionary/person/nrj.txt
>       翻译人名
>       data/dictionary/person/nrf.txt
>       #繁简词典路径
>       TraditionalChineseDictionaryPath=data/dictionary/tc/TraditionalChinese.txt
>       #自定义词典路径，用;隔开多个自定义词典，空格开头表示在同一个目录，使用“文件名 词性”形式则表示这个词典的词性默认是该词性。优先级递减。
>       #另外data/dictionary/custom/CustomDictionary.txt是个高质量的词库，请不要删除
>       CustomDictionaryPath=data/dictionary/custom/CustomDictionary.txt; 现代汉语补充词库.txt; 全国地名大全.txt ns; 人名词典.txt; 机构名词典.txt; 上海地名.txt ns;data/dictionary/person/nrf.txt nrf
>       #CRF分词模型路径
>       CRFSegmentModelPath=data/model/segment/CRFSegmentModel.txt
>       #HMM分词模型
>       HMMSegmentModelPath=data/model/segment/HMMSegmentModel.bin
>       #分词结果是否展示词性
>       ShowTermNature=true
>
>
>
>
>
>


- **待续：**
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
