### NLP-HanLP -- HMM vs CRF
- **概述**：
>       参考：https://www.cntofu.com/book/85/ml/crf/crf.md
>       crf vs hmm：
>           CRF就是一个反向的隐马模型hmm，两者都是用了马尔科夫链作为隐含变量的概率转移模型；
>           hmm使用隐含变量生成可观测状态，其生成概率由标注集统计得到，是一个生成模型，求解的是联合概率
>               是在对观测序列做了马尔科夫假设的前提下建立联合分布的模型
>           CRF反过来通过可观测状态判别隐含变量，其台率亦通过标注集统计得来，是一个判别模型，求解的是条件概率
>               linear-CRF是利用最大熵模型的思路去建立条件概率模型，对于观测序列并没有做马尔科夫假设
>           由于两个模型的主干相同，其能够应用的领域往往是重叠的，crf在句法分析和NER更胜一筹
>           HMM/CRF是对数线性模型
>           比如在词性标注中：
>               HMM的思路是用生成办法，就是说，在已知要标注的句子s的情况下，去判断生成标注序列l的概率
>
>           crf相对hmm的优势：
>               hmm仅能根据p(y_i|y_i-1)和p(x|y)连个特征去进行训练得到联合分布
>               crf可以定义多个特征函数，也可以在特征函数中定义y_i-1,y_i,x_k，即与当前的标签、之前的标签、和每个输入x都有关系，还可以定义不同的组合
>
>
>       生成模型和判别模型：
>           生成模型学习联合概率分布P(y,x)，而判别模型学习条件概率分布p(y|x)
>           主要区别在于模型中观测序列x和状态序列y之间的决定关系，生成模型假设y决定x，判别模型假设x决定y
>           判别模型：
>               由数据学习条件概率分布p(y|x)作为预测的模型
>               判别模型符合传统的模型分类思想，人呢为输出序列y由输入序列x决定，直接对后验概率p(y|x)进行建模
>               代表性的判别模型：
>                   最大熵模型、条件随机场、支持向量机、最大熵马尔可夫模型、感知机等
>           生成模型：
>               由数据学习联合概率密度分布p(x,y)，然后求出条件概率分布p(y|x)作为预测的模型，即p(y|x)=p(y,x)/p(x)
>               生成模型认为输出序列y按照一定的规律生成输入序列x，也即认为同一分类结果对应的输入具有一定规律，针对联合概率分布p(x,y)进行建模，并且通过估计使生成概率最大的生成序列来获取y
>               代表性的生成模型：
>                   n元语法模型、HMM、朴素的贝叶斯分类器、概率上下文无关文法等
>
>
>       crf vs logistics：
>           条件随机场是逻辑回归的序列化版本，逻辑回归是用于分类的对数线性模型，CRF是用于序列化标注的对数线性模型
>
>
>

- **CRF：**
>       CRF：
>           CRF是给定一组输入序列条件下另一组输出序列的条件概率分布模型
>
>       随机场到马尔科夫随机场：
>           随机场就是每一个位置按照某种分布随机赋予一个值，其全体就叫随机场
>           **马尔科夫随机场是随机场的特例**，假设某一个位置的赋值仅仅与它相邻位置的赋值有关，如第三个词的词性除了与自己本身的位置有关，只与第二个和第四个词的词性有关
>
>       从马尔科夫随机场到条件随机场：
>           CRF是马尔科夫随机场的特例，它假设马尔科夫随机场只有X和Y两种变量，X一般是给定的，而Y一般是在给定X的条件下我们的输出，这样马尔科夫随机场就变成了条件随机场
>           用数学语言描述：
>               设X和Y是随机变量，P(Y|X)是给定X的Y的条件概率分布，若随机变量Y构成的是一个马尔科夫随机场，则称条件概率分布P(Y|X)是条件随机场
>
>       从条件随机场到线性链条件随机场：
>           在CRF中，没有要求X和Y具有相同的结构。而现实中一般假设X和Y有相同的结构。X和Y有相同的结构的CRF就构成了线性链条件随机场，
>           比如十个词的句子中的词性标注，词有10个，词性也是10个，因此如果假设它是一个马尔科夫随机场，那么它也就是一个线性链条件随机场
>           线性链条件随机场：
>               如果X和Y均为线性链表示的随机变量序列，在给定随机变量序列X的情况下，随机变量Y的条件概率分布P(Y|X)构成条件随机场，即马尔科夫性，则称P(Y|X)为线性链条件随机场
>
>       linear-CRF的参数化形式：
>           通过特征函数和权重系数来定义可以学习的机器学习模型。
>           每个特征函数定义了一个linear-CRF的规则，其系数定义了这个规则的可信度。所有的规则和可信度一起构成了linear-CRF最终的条件概率分布
>
>       linear-CRF的三个基本问题：
>           评估：
>               给定linear-CRF的条件概率分布P(y|x)，在给定输入序列x和输出序列y时，计算条件概率P(y_i|x)和P(y_i-1,y_i|x)以及对应的期望
>           学习：
>               给定训练数据X和Y，学习模型参数w_k和条件概率P(y|x)，这个比hmm简单，普通的梯度下降和拟牛顿法都可以解决
>           解码：
>               给定条件概率分布P(y|x)和输入序列x，计算是条件概率最大的输出序列y，类似于hmm，可以使用viterbi解决
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>

- **待续：**
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
