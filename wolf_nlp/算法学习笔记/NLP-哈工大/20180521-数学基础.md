### 哈工大NLP -- 数学基础和语言学基础
- **概述：**：
>       数学、语言学和计算机科学是是三个联系最密切的学科
>
>


- **数学：**：
>       社会学、社会计算、心理学、应用心理学、情感分析等数学与其他科学的融合
>
>       模型：
>           重要的模型：1、隐马模型  2、最大熵模型
>           分成两类：
>               生成模型：隐马模型
>               条件判别模型：最大熵模型
>
>       统计语言步骤：
>           收集自然语言词汇的分布
>           进行统计推导(构造统计语言模型)
>
>       概率论：研究随机现象的数学分支
>
>       语言统计分布规律：
>           少数高频词占用大部分比例
>
>
>       1、汉字的信息熵：
>           不确定性的信息量度计算信息公式
>           应用：接收到英文讯号消除的不确定程度是4.16比特，根据英文字符统计概率，然后根据信息熵公式计算得出
>               汉字单个字符是9.52比特，汉字是当今世界上信息量最大的文字符号系统，汉字是世界上硕果仅存的象形文字
>
>       2、条件概率：
>           先验概率：非条件概率， 比如，P(A)
>           后验概率：条件概率，比如，P(A|B)
>           联合概率：P(A,B)=P(A)P(B|A)=P(B)P(A|B)
>               arg x maxf(x)表示使f(x)值为最大的的那个x的值
>           联合概率的链式规则：
>               P(A,B,C,D...)=P(A)P(B|A)P(C|A,B)P(D|A,B,C...)
>           条件独立：
>               两个事件A和B是在条件C下相互条件独立的，则有P(A|C)=P(A|B,C)
>           贝叶斯定理(核心地位)：
>               P(A|B)=P(B|A)*P(A)/P(B)
>               例如：音字转换
>           随机变量：
>               离散型和连续型
>           数学期望和方差：
>               期望：随机变量的均值
>               方差：描述彼此之间的差距大小
>               例如：统计两个字之间的距离(字数)方差，判断两个字是否能构成一个词，发现新词中
>           阈值：
>               少用阈值
>           构造语言模型的两种方法：
>               基于频度的统计
>                   有参数的方法 （某种语言现象服从某种分布，概率分布，如二元分布、正态分布(高斯分布)、泊松分布等概率模型 求参数）
>                   无参数方法 （没有预先预设的分布，没有先验概率，通常采用最大相似度来估算，!!! 比较常用 !!!）
>               贝叶斯统计（可信度的数量化）
>                   可信度的数量化，指在引入新的训练语料得出的模型比之前的模型可信度更高
>
>
>
>
>
>

- **语言学基础：**
>       面向信息处理的词语分类体系：
>           实词（开放类，指数量在不断在增加、位置不固定等）
>               体词（一般做主语、宾语）
>               谓词（）
>           虚词（封闭类）
>               介词
>               连词
>               助词
>               语气词
>           拟声词
>           叹词
>           其他类
>
>       汉语句法分析特点：
>           汉语句法分析的特殊性
>           同一词类可担任多种句法成分且无形态变化
>           汉语句子构造规则与短语构造规则基本一致（出自朱德熙的语法讲义）
>
>       语言知识库：
>           简单的算法 + 庞大的语言知识库
>           音字转换词典
>           语义词典
>           术语库
>           现代汉语短语结构规则库
>           古代诗词语料库
>
>       ontologic：
>           本体论
>
>       Hownet(知网)：
>           语义词典
>           义原定义词汇的结构
>           原来为机器翻译做出的模型，后来为语义分析产生的各种模型
>           语义定义，同义、反义集合等
>           义原，义原之间的关系构成语义联系
>
>       语义相似度计算：
>           基于语言知识库的语义相似度计算（如使用hownet计算）
>           基于统计的语义相似度（如word2vec）
>
>       构造语言知识库：
>           词典（机器可读词典）
>           词表（Lexicon，音字转换、语音识别等词典）
>               文本文件（知识产权和效率）
>               数据库（有些地方不适用）
>               二进制文件（推荐使用）
>
>           wordid 将词转化为id操作
>           tree或hash操作
>
>
>


- **待续：**
>
>
>
>
>
>
>
>
>
>
>
>
