## NLP-工程应用 - 实际工程应用
- **概述：**
>       **!!!!!数据和特征决定机器学习的上限，模型和算法只是逐渐逼近上限!!!!!!!!!!!**
>
>       如果你想要真正提高你的系统 短期内把把时间花在寻找更大的数据 理解问题以更好的做feature engineering 会比寻找fancy的算法有效的多。！！！
>
>
>

- **训练网络的时候内存爆炸：**
>       训练网络的时候内存爆炸，可以减小batch_size
>
>
>

- **句子相似度分析：**
>       word2vec+ap聚类和tf-idf+lsi做句子的相似度分析
>

- **LDA算法的应用：**
>       LDA是目前一个经典和热门的算法，百度的商务搜索里面就用了不少这方面的算法
>

- **模型评估：**
>       相似度评估：
>           1、我现在在工程上分别用word2vec+ap聚类和tf-idf+lsi去做句子之间的相似度分析，然后分组，但看上去，这是一个无监督学习的问题，
>               我用什么方法去evaluate我这个模型方法的优劣会比较好呢
>               例子：https://datum.readthedocs.io/en/latest/201308/gensim.html#lsi
>
>
>

- **语言模型训练工具：**
>       1、SRILM（http://www.speech.sri.com/projects/srilm/）
>           从1995年开始由SRI 口语技术与研究实验室（SRI Speech Technology and Research Laboratory）开发，现在仍然不断推出新版本，被广泛应用于语音识别、机器翻译等领域
>       2、IRSTLM（http://hlt.fbk.eu/en/irstlm）
>           IRSTLM是意大利Trento FBK-IRST实验室开发的语言模型训练工具包，其开发的目的是处理较大规模的训练数据，在大规模语言模型的训练和使用上，IRSTLM较SRILM有较大的优势，其内存消耗仅是SRILM的一半
>       3、MITLM（http://code.google.com/p/mitlm/）
>           mitlm的资料很少，貌似没有人维护和更新了
>       4、BerkeleyLM（http://code.google.com/p/berkeleylm/） https://github.com/adampauls/berkeleylm
>            资料不多，没怎么维护和更新了
>       5、kenlm （https://github.com/kpu/kenlm） （加号推荐）
>
>
>
>
>

- **其他：**
>       模型调优经验：
>           预训练+微调是现在的主流啊
>           分享一下我最近调优的经验，欠拟合，首先可以提高数据的表征维度（NLP，词向量维度），观察不同迭代数的效果，
>               数据的预处理是否干净，变换样本的长度，引入预训练数据。还有，提高数据集的size
>           对于nlp这块，你的embeddings初始化的时候是随机的，但你可以引入预训练词向量代替随机初始化，
>               因为这部分数据是之前预训练模型调整过的，对你后期的模型还是有帮助的
>
>       怎么从新闻标题中找出大众的感兴趣的词（已知点击数和投放数）？
>           用的统计词频，效果不太好
>           那么可以建模成为分类问题，然后看某个词对应的权值
>           几个方案吧，把你的文章分为2类，比如说点击与未点击，然后直接看每个词的信息增益，或者卡方值之类的。
>           还有的做法是，把你的文本one-hot编码，然后输入xgb，分类器，目标是点击与否，然后输出特征重要性
>           还有做法是用深度学习的self-attention，看self-attention的权值哪个最高
>           直觉上看分类任务来提权重应该更鲁棒一点
>
>           毕竟如果你做点击预测，那势必那些曝光高的文章点击也多，相反曝光低的文章曝光也低
>           这样训练似乎会抓出那些高曝光的关键词
>
>
>
>

- **待续：**
>
>
>
>
>
>
>
>
>
>
>
