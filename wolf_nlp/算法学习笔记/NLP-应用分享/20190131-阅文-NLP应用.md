## NLP-应用分享 - NLP在网络文学领域的应用
- **概述：**
>
>       本文主要介绍以下内容：
>           1、技术架构
>           2、落地实践
>
>

- **技术架构：**
>
>       如下图，
> ![avatar](https://github.com/nwaiting/wolf-ai/blob/master/wolf_others/pic/yuewen_architecture.jpg)
>
>       1、知识库构建
>           知识库主要用于辅助语义理解、关系网络构建和知识推理。
>           a、知识库可以辅助网络内容进行语义理解，并希望把这些知识库固化下来进行迭代更新；
>           b、以及相应的角色和角色之间的关系，把关系网络建立起来；
>           c、当需要大规模、系统化的深层关系挖掘时，可通过知识库来支持知识推理。
>
>       2、知识库构建方法
>           知识库构建主要有两种：
>           a、基于数据推理
>               基于数据推理的方法需要大量的算法辅助
>           b、基于人工构建
>

- **落地实践：**
>
>       1、角色分析
>           角色分析主要通过NER加关系抽取进行分析。
>           NER实体：
>               主要是书籍主角识别
>               书籍主角名识别最简单的一种方法是通过关键词 + 词性 + 百家姓来分析角色，这种方法可以达到95.6%
>           人物关系分析：
>               人物社交关系通过社交比例进行量化，与人物A有社交关系的所有人除以书中人物总和，即人物A的社交比例。
>               人物关系矩阵中，通过统计人物贡献周围的一些词是正向还是负向来判断人物是正面人物还是反面人物。通过人物关系矩阵，进一步加工关系向量，再利用关系向量聚类，就可以进行分类。
>               如下图，
> ![avatar](https://github.com/nwaiting/wolf-ai/blob/master/wolf_others/pic/yuewen_people_relationship_semantic.jpg)
>
>       2、标签建设
>           标签的生成主要有两种方法，
>           a、基于规则产生
>               缺点：规则不好定义，规则中的词存在歧义，不同场景中上下文有不同的意思
>           b、基于相似度产出
>               相似度有两类：
>               (1)、语义相似度
>                   包含标签语义向量生成和书籍语义向量生成
>               (2)、特征向量相似度
>                   通过用户行为的相关性对标签进行预测
>           结合规则特征、结构特征和语义特征，使用深度学习进行建模。
>           缺点：
>               当标注不完整的情况下，多标签如何联合建模的问题
>           如下图，
> ![avatar](https://github.com/nwaiting/wolf-ai/blob/master/wolf_others/pic/yuewen_labels_model.jpg)
>
>       3、推荐语生成
>       4、色情鉴别
>           主要判断内容是否涉黄、涉政、涉黑等，鉴别方法主要有两种：
>           a、关键词召回
>               需要定义风险召回关键词和黑名单等
>           b、模型召回
>               使用的特征包括规则粒度特征、结构特征和语义特征
>               也可以使用word2vec进行特征扩展，但同时会引入大量噪音
>           如下图，
> ![avatar](https://github.com/nwaiting/wolf-ai/blob/master/wolf_others/pic/yuewen_pornographic_identify.jpg)
>
>       5、抄袭鉴别
>           抄袭一般会对关键词和命名实体进行替换。
>           基于这种原因，在做抄袭时，把句子中的部分关键词和命名实体识别去除，只提取常用词典中的词，减少命名实体、时间名词的干扰。
>
>           具体算法有：
>               章节拆分：
>                   以句子为最小单位，判断不同章节中句子是否有重复
>               句子筛选：
>                   删除短句，只保留长句。原因是加入短句会使得最后的命中结果太多
>               去除长句中的命名实体：
>                   保留常用词，减少实体词的干扰
>               提取指纹：
>                   通过MD5等，对每个长句提取唯一的指纹，得到该章节的所有指纹集合
>               建立索引：
>                   通过Lucene对指纹建立倒排表
>
>               如下图，
> ![avatar](https://github.com/nwaiting/wolf-ai/blob/master/wolf_others/pic/yuewen_repeat_identify.jpg)
>
>           鉴别时，先对章节进行预处理，利用Lucene索引对比指纹库，如果被找到的句子数超过一定的阈值，则认为该文章为抄袭文章。
>
>

- **实践总结：**
>
>       如何快速构建正负样本。样本标注不是硬标注，应结合技术手段尽可能减少标注的工作量（例如谷歌流体标注改造），标注尽可能使用二值判断的方式，
>           避免使用从多个选项中选择一个的方式。另一点是配套监控与记录、校验，确保整个标注过程可控。
>
>       如何充分利用用户行为。不要觉得用户行为是无效的，用户行为能提供很多信息。
>           文本本身是通过共识达成的，而用户行为记录的是更本质的共识系统。如果业务上会产出用户行为，则优先考虑用户行为贡献的知识。
>           用户行为表明两个item相关，就不要单纯从NLP语义上去判断说不相关。将行为融入到NLP分析模型中，也是后续的发展方向。
>
>
>
>
>
>
>
>

- **待续：**
>       参考：https://mp.weixin.qq.com/s/XVOVsccCqNS4ki_lDGajtQ
>
>
>
>
>
>
>
