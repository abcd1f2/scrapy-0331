### NLP_总结 -- 学习索引
- **概述**：
>       NLP学习知识点见下图
>![avatar](https://github.com/nwaiting/wolf-ai/blob/master/wolf_others/pic/nlp_keys.jpg)
>
>       NLP以及文本相关如下图
>![avatar](https://github.com/nwaiting/wolf-ai/blob/master/wolf_others/pic/nlp_text.jpg)
>
>       按照图中文本算法的索引，总体分为五个部分：
>           1、自然语言处理
>           2、搜索引擎
>           3、文本基础
>           4、数理基础
>           5、机器学习
>
>

- **NLP常见算法与模型：**
>       1、语言模型
>       2、MaxEnt/CRF/EM/HMM
>       3、pLSA/LDA
>       4、word2vec
>       5、fasttext
>       6、LSTM/RNN
>       7、文本分类、聚类、摘要算法
>

#### 以下是NLP的相关技能
- **自然语言处理基础知识与操作：**
>       第1章 自然语言处理基础
>       •	1.1 文本数据、字、词、term
>       •	1.2 字符串处理
>       •	1.3 模式匹配与正则表达式
>       •	1.4 【实战】字符串基本处理与正则表达式文本匹配与替换
>       第2章 英文文本处理与解析
>       •	2.1 英文文本处理任务介绍：分词、去停用词、提取词干
>       •	2.2 英文文本解析任务介绍：词性分析、依赖分析、命名实体识别
>       •	2.3 【实战】NLTK工具库英文文本处理案例
>       •	2.4 【实战】spaCy工具库英文文本处理案例
>       •	2.5 【实战】基于python的英文文本相似度比对
>

- **自然语言处理基础知识与操作**
>       第1章 语言模型与应用
>       •	1.1 假设性独立与联合概率链规则
>       •	1.2 N-gram语言模型
>       •	1.3 N-gram应用：词性标注、中文分词、机器翻译与语音识别
>       第2章 统计语言模型与神经语言模型构建
>       •	2.1 基于统计的语言模型构建
>       •	2.2 【实战】KenLM工具库使用及语言模型生成
>       •	2.3 【实战】基于KenLM的简易拼写纠错
>       •	2.4 【实战】基于RNN的神经语言模型
>       •	2.5 【实战】基于pytorch的语言模型训练
>

- **文本表示**
>       第1章 文本词与句的表示
>       • 1.1 文本表示概述
>       • 1.2 文本离散表示：词袋模型与TF-IDF
>       • 1.3 文本分布式表示：word2vec
>       • 1.4 【实战】python中文文本向量化表示
>       • 1.5 【实战】基于gensim的中文文本词向量训练与相似度匹配
>       第2章 文本表示进阶
>       • 2.1 预训练在图像领域的应用
>       • 2.2 ELMO：基于上下文的embedding
>       • 2.3 GPT: Transformer特征抽取
>       • 2.4 BERT：预训练双向Transformer
>       • 2.5【实战】基于BERT进行fine-tuning
>

- **文本分类**
>       第1章 文本分类机器学习模型与实战
>       •	1.1  朴素贝叶斯模型与中文文本分类
>       •	1.2  逻辑回归/SVM与文本分类
>       •	1.3  facebook fasttext原理与操作
>       •	1.4 【实战】python中文新闻分类
>       •	1.5 【实战】基于fasttext的文本情感分析
>       第2章 文本分类深度学习模型与实战
>       •	2.1 词嵌入与fine-tuning
>       •	2.2 基于卷积神经网络的文本分类
>       •	2.3 基于LSTM的文本分类
>       •	2.4 【实战】使用tensorflow构建卷积神经网络完成新闻分类
>       •	2.5 【实战】使用tensorflow构建LSTM完成影评褒贬分析模型
>

- **文本主题抽取与表示**
>       第1章 文本主题抽取与表示
>       •	1.1 基于tf-idf与text-rank的主题词抽取
>       •	1.2 无监督学习与LDA主题模型
>       •	1.3 监督学习与文本打标签
>       •	1.4 【实战】基于python的中文关键词抽取与可视化
>       •	1.5【实战】基于LDA的新闻主题分析与可视化呈现
>

- **序列到序列模型(seq2seq model)**
>       第1章 序列到序列模型与应用
>       •	1.1 从RNN到seq2seq模型
>       •	1.2 编码解码模型
>       •	1.3 seq2seq模型详解
>       •	1.4 注意力(attention)机制
>       •	1.5 【实战】tensorflow seq2seq模型使用方法详解
>       •	1.6 【实战】基于seq2seq的文本摘要生成实现
>

- **文本生成**
>       第1章 文本生成与自动创作
>       •	1.1 基于RNN/LSTM的语言模型回顾
>       •	1.2 基于语言模型的文本生成原理
>       •	1.3 基于seq2seq的文本生成原理
>       •	1.4 【实战】基于LSTM的唐诗生成器
>       •	1.5 【实战】基于seq2seq的歌词生成器
>

- **机器翻译**
>       第1章 统计机器翻译
>       • 1.1 词、句子和语料与基本概率论知识
>       • 1.2 翻译模型与语言模型
>       • 1.3 解码与beam-search
>       • 1.4 翻译系统评估
>       • 1.5 【实战】moses统计翻译系统实战
>       第2章 基于seq2seq的机器翻译模型
>       • 2.1 基础seq2seq编解码模型机器翻译应用
>       • 2.2 基于注意力机制的seq2seq机器翻译优化
>       • 2.3【实战】基于keras完成的基础seq2seq机器翻译模型
>       • 2.4【实战】基于tensorflow的google版seq2seq机器翻译模型
>       第3章 facebook基于CNN的机器翻译模型
>       • 3.1 【课程】基于CNN的翻译系统模型结构
>       • 3.2 【课程】使用CNN完成神经翻译系统的tricks
>       • 3.3【实战】facebook CNN机器翻译系统代码解析
>       第4章 来自Google的Transformer模型
>       • 4.1 来自Google的Transformer模型
>       • 4.2 Transformer模型的训练细节
>       • 4.3 【实战】Transformer源码解析
>


- **聊天机器人**
>       第1章 基于内容匹配的聊天机器人
>       •	1.1 基于文本字面匹配的聊天机器人
>       •	1.2 借助深度学习进行语义抽取匹配的聊天机器人
>       •	1.3 【实战】Chatterbot聊天机器人工具库简易使用
>       •	1.4 【实战】基于深度学习匹配的聊天机器人实现
>       第2章 基于seq2seq的聊天机器人
>       •	2.1 seq2seq用于聊天机器人场景的原理
>       •	2.2 数据处理与准备
>       •	2.3 模型构建与优化细节
>       •	2.4 【实战】基于tensorflow的seq2seq聊天机器人构建
>

- **视觉文本任务**
>       第1章 看图说话问题与实现
>       • 1.1 “看图说话”问题介绍
>       • 1.2 简易CNN+RNN编码解码模型完成图片短文本描述原理
>       • 1.3 注意力模型与“看图说话”优化
>       • 1.4 【实战】基于CNN+RNN的编解码“看图说话”与beam-search优化
>       • 1.5 【实战】基于attention model的“看图说话”实现
>       第2章 视觉问答机器人(VQA)原理与实现
>       • 2.1视觉问答机器人问题介绍
>       • 2.2基于图像信息和文本信息抽取匹配的VQA实现方案
>       • 2.3基于注意力(attention)的深度学习VQA实现方案
>       • 2.4【实战】使用keras完成CNN+RNN基础VQA模型
>       • 2.5【实战】基于attention的深度学习VQA模型实现
>

- **文本相似度计算与文本匹配问题**
>       第1章 文本相似度问题与应用场景
>       •	1.1 文本相似度问题
>       •	1.2 文本相似度应用场景：问答系统、对话系统、信息检索
>       •	1.3 传统文本相似度计算方式：编辑距离、simhash、word2vec
>       •	1.4 【实战】编辑距离计算python实现
>       •	1.5 【实战】基于simhash的相似文本判断
>       第2章 基于深度学习的文本语义匹配
>       •	2.1基于深度学习的语义表达方法
>       •	2.2 DSSM（Deep Structured Semantic Models）模型详解
>       •	2.3 DRMM（Deep Relevance Matching Model）模型详解
>       •	2.4【实战】基于LSTM的监督学习语义表达抽取
>       •	2.5【实战】基于DSSM的问题语义相似度匹配案例
>       •	2.6【实战】基于DRMM的问答匹配案例
>
>
>
>
>
>
>
>
>
>
>
>

- **待续：**
>
>
>
>
>
>
>
>
>
>
