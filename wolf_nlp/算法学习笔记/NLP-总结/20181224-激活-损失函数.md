### NLP_总结 -- 激活函数和损失函数
- **概述**：
>
>
>
>
>
>
>
>

- **激活函数：**
>       1、sigmoid
>       2、softmax
>       3、tanh
>       4、rectified linear
>
>
>
>
>
>
>

- **损失函数：**
>       1、二次损失函数
>           如果神经元的房产是线性的，则用二次cost函数不会有学习慢的问题
>       2、交叉熵损失函数
>           cross-entropy cost几乎总是比二次cost好
>       3、对数似然函数
>
>
>
>
>
>
>
>
>
>
>
>

- **待续：**
>       参考：https://nlpcs.com/category/NLP   
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
