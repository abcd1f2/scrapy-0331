### NLP_总结 -- 激活函数和损失函数
- **概述**：
>       激活函数作用：
>           1、加入了非线性因素
>           2、充分组合特征
>
>       损失函数：
>           损失函数度量模型一次预测的好坏
>
>
>
>

- **激活函数：**
>       1、sigmoid
>       2、softmax
>       3、tanh
>       4、rectified linear
>       5、ReLU
>       6、LeakyReLU
>       7、pReLU
>       8、ELU
>       9、maxout
>
>
>

- **损失函数：**
>       常见的损失函数：
>           softmax、logistic loss、hinge loss（用于最大化间隔分类器中）、
>       1、二次损失函数
>           如果神经元的房产是线性的，则用二次cost函数不会有学习慢的问题
>       2、交叉熵损失函数
>           cross-entropy cost几乎总是比二次cost好
>       3、对数似然函数
>
>
>
>
>
>
>
>
>
>
>
>

- **待续：**
>       参考：https://nlpcs.com/category/NLP
>           https://www.cnblogs.com/makefile/p/loss-function.html   损失函数
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
