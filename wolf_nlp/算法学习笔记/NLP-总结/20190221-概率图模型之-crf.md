## NLP_总结 -- 概率图模型之-crf
- **概述**：
>
>
>
>
>
>

- **crf学习**
>
>       1、cost函数：
>           通过极大化对数似然函数，求得参数值
>           如下图
> ![avatar](https://github.com/nwaiting/wolf-ai/blob/master/wolf_others/pic/pgm_crf_cost_function.png)
>           其中，p~(x,y)表示训练样本集中xy的经验概率，即xy同时出现的次数除以样本空间容量；
>               p~(x)表示训练样本集中x的经验概率，它等于x出现的次数除以样本空间容量
>
>           如下图是李航老师的<<统计学习方法>>
> ![avatar](https://github.com/nwaiting/wolf-ai/blob/master/wolf_others/pic/pgm_crf_cost_function2.png)
>
>       2、优化方法：
>           极大似然估计
>           梯度下降
>           牛顿迭代法
>           拟牛顿法
>           BFGS
>           LBFGS
>
>

- **CRF应用：**
>
>       CRF++源码中为防止过拟合，CRF++采用了L1或L2正则化，供选择，
>           使用了lbfgs进行优化
>
>
>
>
>

- **吉布斯分布：**
>
>       吉布斯分布：
>           吉布斯分布起源于统计物理学，它确定了任何宏观物体的统计分布，这个宏观物体是某个大的闭合系统的比较小的一部分。分布称为吉布斯分布。
>           没有物理背景的马尔科夫随机场也会在形式服从吉布斯分布(根据Hammersley-Clifford定理)
>

- **crf-vs-MaxEnt**
>
>       1、在序列标注任务中，
>           由于crf和me建模思想不同，两个模型是从不同角度来解决标注问题。最大熵模型的特征函数可以定义成和CRF一样，考虑上一个标注结果yi-1，
>               但事实上模型在输出时依旧只关注当前的yi，即CRF通过viterbi解码得到一个全局最优解，而最大熵模型仅仅只是使得每个yi最优。
>               CRF和最大熵有着本质的区别，CRF是对整个序列进行建模而最大熵只是对每个单独的标注样例进行建模。
>               （从Z(x)可以看出，CRF模型中Z(x)是对整个序列所有输出情况进行求和，而最大熵仅仅只是对有多少种标注类别进行求和）
>               因此在序列标注问题上，CRF模型由于最大熵模型，但是计算开销更大。
>           MaxEnt：
>               将这个问题看做是分类问题（即输入当前词的特征，然后由ME模型给出一个类别标签）
>           CRF：
>               将这个问题看做是序列标注问题（CRF会对整个序列进行建模）
>
>
>
>
>
>
>
>
>


- **待续：**
>       参考：http://academic.hep.com.cn/fib/EN/chapter/978-7-04-030572-2-00/chapter03     第三章 吉布斯分布（统计物理学）
>           https://www.jianshu.com/p/9e116a3a9222  重新认识吉布斯分布
>
>
>
>
>
>
>
>
>
>
>
>
>
