### NLP汉语自然语言处理原理与实践-文本分类
- **概述：**
>       **!!!!!数据和特征决定机器学习的上限，模型和算法只是逐渐逼近上限!!!!!!!!!!!**
>
>       工业界文本处理现状：
>       在NLP领域，深度学习技术取得的效果有限（毕竟语言是高阶抽象的信息，深度学习在图像、语音这些低阶具体信息的处理上更合适，因为低阶具体信息构造特征是一件费力的事情）
>       工业界现在通常的做法都是会把深度学习模型作为系统的一个子模块（也是一维特征），和一些传统的基于统计的自然语言技术的特征，还有一些针对具体任务本身专门设计的特征，
>       一起作为一个或多个模型（也称为Ensemble，即模型集成）的输入，最终构成一个文本处理系统。
>
>
>       文本分类的应用场景：
>           1、按题材进行自动分类，如对新闻网站的报道文章内容，进行划分为政治、经济、军事、体育、娱乐等
>           2、评价分类，电商或者其他评论中，对评论进行情感分类
>           3、垃圾邮件分类，对邮件进行分类
>           4、对媒体投稿邮件分类，对文章进行自动审核，标记投稿中的色情、暴力、政治等
>
>        传统的机器学习算法基本过程：
>           1、标注数据
>           2、特征抽取
>               可以将词频小于一定大小的词频删除，减小特征维度
>           3、训练模型
>               bayes、SVM、knn、nn、decision tree
>           4、分类预测
>
>       最常见的两种文本分类问题：
>           1、文本按主题归类（比如将所有介绍亚运会的新闻归到体育类）
>           2、将词汇表中的字词按意思归类（比如将各种体育运动的名称各归成一类）
>           这两种分类问题都可通过矩阵运算来圆满地、同时解决。
>           https://wenku.baidu.com/view/cb373a1c5f0e7cd184253634.html  lecture18-lsi 信息检索导论 王斌 PPT 课件 第18章_百度文库
>
>       文本分类中出现的问题：
>           1、一词多义
>               bank（银行、河岸）、apple（水果、公司）
>           2、一义多词
>               automobile（汽车），实际上包含car的页面也是用户需求
>
>       线性和非线性分类器：
>           线性分类器：模型是参数的线性函数，分类平面是（超）平面；
>                   典型的线性分类器有感知机，LDA，逻辑斯特回归，SVM（线性核）；
>
>           非线性分类器：模型分界面可以是曲面或者超平面的组合。
>                   典型的非线性分类器有朴素贝叶斯（有文章说这个本质是线性的，http://dataunion.org/12344.html），kNN，决策树，SVM（非线性核）
>
>
>

- **文本分类的要点：**
>       **文本分类的核心就是如何从文本中抽取出能够体现文本特点的关键特征，抓取特征到类别之间的映射关系。**！！！！
>
>

- **文本特征：**
> [详情](https://github.com/nwaiting/wolf-ai/blob/master/wolf_nlp/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/NLP-%E6%80%BB%E7%BB%93/20181225-%E6%96%87%E6%9C%AC%E7%89%B9%E5%BE%81.md)
>
>
>
>
>
>
>
>

- **TF-IDF**
>       评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度
>       tf-idf算法的精度不是很高，因为比如在web文档中，html中不同位置的词对文章内容的反映程度不同，其权重的计算方法也应不同。
>
>
>
>
>
>
>
>
>
>

- **LSI算法：**
>       https://blog.csdn.net/zhongkejingwang/article/details/43053513?utm_source=blogxgwz0     奇异值分解(SVD)原理详解及推导
>       http://www.cnblogs.com/LeftNotEasy/archive/2011/01/19/svd-and-applications.html     机器学习中的数学(5)-强大的矩阵奇异值分解(SVD)及其应用
>       https://blog.csdn.net/m0_37681914/article/details/73810644      gensim 之 td-idf和lsi模型
>       https://blog.csdn.net/abcjennifer/article/details/8131087       奇异值分解SVD应用——LSI
>       参考：https://cloud.tencent.com/developer/article/1079043      达观数据分享文本大数据的机器学习自动分类方法
>
>
>
>
>
>
>

- **奇异值分解SVD应用 - LSI(Latent Semantic Indexing 潜在语义搜索)**
>       **LSI算法被用于Google的很多应用，如Adwards，Google suggest，以及反作弊！！！**
>       搜索引擎作弊最快的方法当属关键词堆砌，这源于信息检索中相关算法本身的缺陷。为了对抗这种作弊算法，搜索引擎通过潜在语义搜索（LSI）来发现这些作弊页面。
>       LSI主要用于自然语言理解，通过统计的方法对文档进行语义分析，发掘同义词、相关词组等
>
>
>
>
>

- **LDA(Linear Discriminant Analysis)算法：**
>       如果学习分类算法，最好从线性的入手，线性分类器最简单的就是LDA，
>       PCA是一个和LDA非常相关的算法，从推导、求解、到算法最终的结果，都有着相当的相似
>       LDA独立性假设太强了，经常不是很work，而且跑起来太慢。但是数学上比较完备，模型漂亮。工程上可以用PLSA。(why)
>
>
>
>


- **文本分类实践应用：**
>
>       各位大佬，在做文本分类中，如果样本数据不均衡，是否可以将特征数据提高权重或者批量生产特征数据来弥补数据不均衡的问题。会不会造成影响啊？
>       答案：
>           
>
>
>
>
>

- **LSA、LSI、LDA文本主题、文本分类**
>       https://www.ziiai.com/blog/719
>
>
>
>
>

- **待续：**
>       参考：http://www.jeyzhang.com/text-classification-in-action.html   文本分类实战系列（一）：特征工程
>
>
>
>
>
