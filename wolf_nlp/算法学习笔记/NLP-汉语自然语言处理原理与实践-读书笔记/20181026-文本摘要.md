### NLP汉语自然语言处理原理与实践-文本摘要
- **概述：**
>       文档、会议、邮件摘要，QA系统回答whar/how等问题，都需要自动摘要技术。
>       摘要形成的两种方式：
>           1、抽取式：
>               摘要句子完全从源文档中抽取形成
>               大多数系统采用的形式
>           2、合成式：
>               从源文档中抽取句子并进行改写形成摘要
>               合成式技术还不够完善
>
>
>

- **抽取式**
>       形成摘要的步骤：
>           1、选择需要抽取的句子
>           2、对抽取的句子进行排序
>           3、形成摘要
>

- **常用的自动文摘方法：**
>       一些研究，如 [Document Summarization using Conditional Random Fields](https://www.semanticscholar.org/paper/Document-Summarization-Using-Conditional-Random-Shen-Sun/72a3efcd92ecbba28ed68e537a86605f57535b3f)和
>       [Enhancing Diversity, Coverage and Balance for Summarization through Structure Learning](http://www2009.org/proceedings/pdf/p71.pdf)
>       对主流的自动文摘方法做了对比，发现
>       1、非监督方法：
>           基于HITS的图模型方法明显优于其他方法，
>       2、监督方法：
>           SVM-HMM和CRF方法效果最好，这两个方法稍微优于HITS图模型方法
>       测试结果：
>           SVM-HMM > CRF > HITS > HMM > SVM > LR > NB > LSA
>
>       基于HITS图模型（非监督）：
>           目前研究表明，基于HITS图模型方法是非监督方法中效果最好的，如果采用非监督方法，则优先考虑HITS图模型
>           优点：
>               无需训练集合
>               基本与语言和领域无关
>               效果好
>           缺点：
>               存在任意句子相似性计算和迭代计算，运行速度慢
>               没有考虑信息冗余问题，可能需要有针对性的优化
>       基于CRF或SVM-HMM（监督学习）：
>           目前研究表明，CRF和SVM-HMM在所有监督和非监督方法中效果最好，其中SVM-HMM优于CRF，CRF优于HITS模型
>           优点：
>               效果好
>           缺点：
>               需要训练数据
>               效果依赖于训练数据质量和领域等方面的情况
>               执行速度慢；尤其是融合HITS模型等复杂特征，需要先计算复杂特征，所以速度应该是最慢的
>
>

- **待续**
>       https://blog.csdn.net/tensorflowshizhan/article/details/69230070    TensorFlow文本摘要生成-基于注意力的序列到序列模型
>       https://github.com/zpppy/seq2seq-chinese-textsum    自动归纳长文本
>       https://github.com/tensorflow/models/tree/master/research/textsum   textsum项目中，用到了seq2seq+attention的深度学习模型，它是Google翻译模型，Google对外宣称准确度达到了97%
>
>
>
>
>
>
>
>
>
>
