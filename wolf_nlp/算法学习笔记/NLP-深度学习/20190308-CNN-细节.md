### 深度学习 - CNN 细节
- **概述**：
>       CNN核心：
>           1、前层卷积层提取基础特征，如边缘、轮廓信息等基础特征
>           2、深层卷积层提取抽象特征，如整个脸型
>           3、全连接层根据特征组合进行评分分类
>
>       相关术语：
>           filter：即kernel
>               卷积核在神经网络里，就代表对应的权重(weight)，卷积核和图像进行点乘，就代表卷积核里的权重单独对相应位置的Pixel进行作用（实际上是位置意义对应的点乘，不是真正意义的卷积）
>               filter的depth对应输入图像的depth
>           feature map:
>               filter的结果对应activetion map或者feature map
>
>       经典的CNN结构：
>           Input -> Conv -> ReLU -> Conv -> ReLU -> Pool -> ReLU -> Conv -> ReLU -> Pool -> Fully Conneted
>
>       其他的CNN网络结构参数：
>           http://blog.geohey.com/chang-yong-de-ji-chong-juan-ji-shen-jing-wang-luo-jie-shao/
>
>
>

- **CNN之卷积：**
>       卷积是分析数学中一种重要的运算。设f(x),g(x)是R上的两个可积函数，作积分：
>           ∫f(τ)g(x-τ)dτ
>       可以证明，关于几乎所有的x∈(-∞,∞)，上述积分是存在的。这样，随着x的不同取值，这个积分就定义了一个新函数h(x)，称为函数f和g的卷积，记为h(x)=(f*g)(x)
>       物理意义大概可以理解为：
>           系统某一时刻的输出是由多个输入共同作用（叠加）的结果。
>       在图像中的理解大概为：
>           f(x)可以理解为原始像素点，所有的原始像素点叠加起来，就是原始图。
>           g(x)可以成为作用点，所有作用点合起来就是我们的卷积核。
>
>       如下图，卷积计算过程：
> ![avatar](https://github.com/nwaiting/wolf-ai/blob/master/wolf_others/pic/nlp_deep_learning_cnn_filter_calculate.jpg)
>       输出结果为特征图(feature map)，所以结果为：
>           W1output = 1*(-1) +1*1+1*0+0*(-1)+1*0+2*1+0*(-1)+1*1+2*(-1) =1
>           W2output = 2*1+2*0+1*1+1*1+0*1+0*2+0*1+0*0+1*1=5
>           W3output = 1*(-1)+1*(-1)+0*(-1)+0*2+0*(1)+0*2+1*0+1*1+0*1 = -1
>           Bias = 0
>           Final_output =W1output + W2output+W3output+bias= 1+5-1+0 = 5
>
>

- **CNN之参数详解：**
>       1、深度depth：
>           神经元个数，决定输出的depth厚度，同时代表滤波器个数
>       2、步长stride:
>           决定滑动多少步可以到边缘
>       3、填充值zero-padding
>           在外围边缘补充若干圈0
>           优点：
>               a、可以获得更多更细致的特征信息，比如图像可以获得更多的边缘信息
>               b、可以控制卷积层输出的特征图的size，从而控制网络结构的作用。
>                  如上图，如果没有zero-padding以及第二层卷积层的卷积核仍然为3*3，那么第二层卷积层输出特征图就是1*1，CNN的特征提取就结束了
>

- **CNN之BN（batch normalization）**
>       BN是将feature map标准化为在0附近，一般在卷积层或者pooling层之后，激活函数之前，因为有些常用激活函数在0附近变化率最大，经过BN之后，
>           特征图像经过激活函数，如sigmoid，被映射到新的特征空间
>       BN有两个优势：
>           1、由于激活函数在0附近变化率大，因此被映射到新的特征空间的特征图也更容易被区别开来，这样既帮助了分类
>           2、同时缓解了梯度消失的问题，消除了梯度更新慢和无序的问题
>
>       注意：
>           大家在用Fine-tune pretrained model，比如Imagenet, 程序里面经常是减去的Imagenet的均值和方差，这样是不对的，大家在跑程序的时候要注意了。！！！
>
>

- **CNN之池化**
>       可以一定程度提高空间不变性，如平移不变性、尺度不变性、形变不变性
>

- **CNN之activation function**
>       激活函数特点：
>           activation function对于提高模型鲁棒性，非线性表达能力，缓解梯度消失的问题，将特征图映射到新的特征空间从而更有利于训练，加速模型收敛等问题有很好的帮助
>
>       常见的activation function如下，
> ![avatar](https://github.com/nwaiting/wolf-ai/blob/master/wolf_others/pic/nlp_deep_learning_cnn_active_function.jpg)
>

- **CNN之FC：**
>       一般有两层或以上的FC，因为如果只有一层FC的话，有时候没办法解决非线性拟合问题，
>       两层或以上的FC就可以很好的解决非线性拟合问题
>
>       从前面的一层一层的下采样，到最后的FC，最后得到最终的分类结果。！！！
>
>       FC参数特别多，可能占整个网络参数的80%左右，近期一些性能优异的模型如ResNet和GoogleNet等均采用全局平均池化(global average pooling,GAP)取代全连接层来融合学到的深度特征。
>       用GAP代替FC的网络通常有较好的预测性能
>
>       FC的特征独立假设：
>           最后使用softmax计算最终的概率时，是在假设不同特征是相互独立的假设前提下，这可能在很多情况下不成立，因为特征之间可能存在协同作用或冗余
>           这种协同或作用会直接影响输出概率，如猫前脚和猫后脚
>           解决方法：
>               1、去除有协同作用或冗余的特征
>               2、当两个特征经常一起被激活时，训练过程将学习较小的权重W1和W2，使得他们的联合效果接近真实效果
>

- **CNN之loss function：**
>       详情见 https://zhuanlan.zhihu.com/p/53045651 详解CNN入门讲解:为什么分类模型 Loss 函数要用 交叉熵Cross Entropy?
>       主要是刻画概率分布越明显，则交叉熵损失越小
>
>       training 过程中，分类问题用 cross entropy，回归问题用 mean squared error
>

- **CNN之模型微调**
>       模型训练从一个预训练模型开始，相对于从头开始训练，微调可以节约提高计算效率，甚至提高准确率。
>       预训练模型就是已经用训练集训练好的模型。现在CNN常用的预训练模型就是其他人常用的模型，如VGG16/19、ResNet等模型，用大量数据集训练好的模型参数
>       正常情况下，常用的VGG16/19等网络已经是有人调试好的优秀网络，无需在修改其网络结构
>
>       普通预训练模型：
>           用了大量数据集做训练，已经具备了提取前层基础特征和深层抽象特征的能力
>
>       什么情况下使用微调：
>           1、数据集相似
>               如果数据集不相似，效果可能就没有那么好
>           2、正确率太低
>               自己搭建的CNN模型正确率太低
>           3、数据集太少
>               数据集相似，但是数量太少
>           4、计算资源太少
>
>       实践经验：
>           在实践中更经常的是，通过对我们拥有的较小数据集进行训练（即反向传播），对现有网络进行微调，这些网络是在像ImageNet这样的大型数据集上进行训练的，以达到快速训练模型的效果。
>           假设我们的数据集与原始数据集（例如ImageNet）的上下文没有很大不同，预先训练的模型将已经学习了与我们自己的分类问题相关的特征。
>
>       模型参数微调经验：
>           1、通常的做法是截断预先训练好的网络的最后一层(softmax层)，并用自己问题相关的softmax层进行替换。
>               如原来的分类是1000类，现在改成自己的分成10类，然后进行训练，确保执行交叉验证，以便网络的推广使用
>           2、使用较小的学习率进行训练
>           3、如果训练数据量太少，可以只训练最后一层
>               如果数据量中等，可以冻结预训练网络的前几层的权重。因为前几层捕捉的是我们新问题相关的通用特征，如曲线和边。
>               我们希望这些权重不变，使网络更专注于学习后续深层中特定于数据集的特征。
>
>       不同数据集下微调经验：
>           1、数据量少，数据相似度高
>               可以只修改最后几层或最终的softmax图层的输出类别
>           2、数据量少，数据相似度低
>               可以冻结预训练模型的初始层（比如k层），对较高层进行重新训练
>           3、数据集大，数据相似度低
>               最好从头开始训练模型
>           4、数据量大，数据相似度高
>               可以保留模型的体系结构和模型的初始权重，可以使用在预先训练的模型中的权重来重新训练模型
>

- **CNN之模型准确率：**
>       置信度和置信区间
>       找到模型的不可靠程度，然后对它的不可靠性进行修正，使模型置信度能够代表真实的概率估计。
>       如何微调，修正不可靠程度？
>           内部：
>               模型输出置信度不能够代表真实的概率估计，说到底还是模型本身的问题，可以调整网络结构
>               比如：增加BN、修改网络层数等，通过实验验证
>           外部：
>               直接对softmax的输出做调整
>               方法1：Calibrating Binary Models：Isotonic regression， Histogram binning，Bayesian Binning into Quantiles，Platt scaling
>               方法2：Calibrating Multiclass Models : Extension of binning methods,Matrix and vector scaling , Temperature scaling
>
>       可供参考方法：
>           Majority Voting with Predefined Confidence Value
>           Step 1 我会用同一套训练数据训练大概30种常用CNN模型，比如Resnet, Xception等等，然后再自己设计20种左右的CNN模型
>           Step 2 从上面50种模型中找出performance表现最好的3种模型，并且这3种模型的结构必须差异化明显，比如以深度为主的Resnet, 和宽度为主的Inception
>           Step 3 对这3个模型再次进行深度调参，直到3个模型达到最优performance
>           Step 4 用这3个模型进行Majority voting
>           于是我会把threshold设置在1.0，因为对我来说，我更希望模型做出判断，尽量是对的，哪怕有很多测试数据没法做出判断也没关系。
>
>
>
>
>
>


- **待续：**
>       参考：
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
