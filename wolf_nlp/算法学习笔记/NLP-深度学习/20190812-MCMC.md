## 深度学习 - MCMC
- **概述**：
>       MCMC（Markov Chain Monte Carlo 马尔科夫链蒙特卡罗）：
>           是一种随机采样方法
>           在机器学习,深度学习以及自然语言处理等领域都有广泛的应用，是很多复杂算法求解的基础
>

- **MC：**
>       MC（蒙特卡罗方法）是一种随机模拟的方法
>       很多时候，x的概率分布不是常见的分布，这意味着没法方便的得到这些非常见的概率分布的样本集
>       由于直接得到概率分布不是很容易，所以使用接受-拒绝采样，可以解决一些概率分布不是常见的分布的时候，得到其采样集并用蒙特卡罗方法求和的目的
>
>       既然 p(x) 太复杂在程序中没法直接采样，那么设定一个程序可采样的分布 q(x) 比如高斯分布，然后按照一定的方法拒绝某些样本，以达到接近 p(x) 分布的目的
>
>       MC在实际中的问题：
>           1、对于一些二维分布p(x,y)，有时候我们只能得到条件分布p(x|y)和p(y|x)和,却很难得到二维分布p(x,y)一般形式，这时我们无法用接受-拒绝采样得到其样本集
>           2、对于一些高维的复杂非常见分布p(x1,x2,...,xn)，我们要找到一个合适的q(x)和k非常困难
>
>       优化：
>           要想将蒙特卡罗方法作为一个通用的采样模拟求和的方法，必须解决如何方便得到各种复杂概率分布的对应的采样样本集的问题
>

- **马尔科夫链模型：**
>       马尔科夫链模型性质：
>           马尔科夫链模型的状态转移矩阵收敛到的稳定概率分布与我们的初始状态概率分布无关
>           采用了不同初始概率分布，最终状态的概率分布趋于同一个稳定的概率分布
>           这个性质对于绝大多数的其他的马尔科夫链模型的状态转移矩阵也有效。同时不光是离散状态，连续状态时也成立
>           对于一个确定的状态转移矩阵P，它的n次幂P^n在当n大于一定的值的时候也可以发现是确定的
>           性质的解释：
>               1、非周期的马尔科夫链：这个主要是指马尔科夫链的状态转化不是循环的，如果是循环的则永远不会收敛。幸运的是我们遇到的马尔科夫链一般都是非周期性的
>               2、任何两个状态是连通的：这个指的是从任意一个状态可以通过有限步到达其他的任意一个状态，不会出现条件概率一直为0导致不可达的情况
>               3、马尔科夫链的状态数可以是有限的，也可以是无限的。因此可以用于连续概率分布和离散概率分布
>
>       马尔科夫链应用：
>           如果得到了这个稳定概率分布对应的马尔科夫链模型的状态转移矩阵，则可以用任意的概率分布样本开始，带入马尔科夫链模型的状态转移矩阵，这样经过一些序列的转换，最终就可以得到符合对应稳定概率分布的样本
>
>
>
>
>
>
>
>
>
>
>
>
>
>

- **待续：**
>       参考：
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
