## NLP_ML - ML算法优缺点比较
- **概述：**
>
>
>

- **常见的一些算法选择：**
>       (仅供参考)
>       NB：
>           优点：
>               对缺失数据不太敏感，常用于文本分类
>               对结果容易解释
>           缺点：
>               需要计算先验概率
>               使用了样本独立假设，所以样本属性有比较大的关联时，效果不一定好
>           应用领域：
>               欺诈检测中使用较多
>               垃圾邮件、文本分类、情感分类等
>       LR：
>           优点：
>               实现简单，计算量小，速度快
>               多重共线性并不是问题，可以结合L2正则化来解决问题
>               容易理解
>           缺点：
>               当特征空间很大时候，逻辑回归性能不是很好
>               不能很好地处理大量多类特征或变量，容易欠拟合，一般准确度不太高
>           应用领域：
>               常用于二分类领域，适用于根据分类概率排名的领域，如排名搜索
>               信用评估
>               测试市场营销的成功度
>               预测地震发生概率
>       线性回归：
>           缺点：
>               不能拟合非线性数据
>       KNN：
>           优点：
>               理论成熟，思想简单，对数据没有假设，准确度高，对outlier不敏感
>           缺点：
>               不平衡数据效果差，需要大量内存，计算量大，每一次分类都要重新进行一次全局计算
>               k值大小的选择没有理论最优值，往往结合K-折交叉验证得到最优k值选择
>           应用领域：
>               文本分类、模式识别、聚类分析、多分类领域
>       决策树：
>           优点：
>               容易解释
>               可以同时处理标称型和数值型特征
>               比较适合处理有缺失属性的样本
>               能处理不相关的特征，运行速度快
>           缺点：
>               容易发生过拟合（可以通过集成模型、剪枝等减少过拟合）
>               容易忽略数据集中属性的相互关联
>               属性划分时（信息增益对可取数目较多的属性有所偏好(如ID3)，增益率对可能数目较少的属性有所偏好）
>           应用领域：
>               企业管理实践、企业投资决策，由于决策树很好的分析能力，在决策过程应用较多
>       SVM：
>           优点：
>               高准确率
>               可以解决高维问题，即大型特征空间，
>               解决小样本下机器学习问题
>               无局部极小值问题（相对于神经网络等算法）
>               泛化能力比较强
>           缺点：
>               内存消耗大，难以解释
>               对缺失数据敏感
>           应用领域：
>               文本分类
>               图像分类
>       K-Means:
>           算法的核心就是要优化失真函数J,使其收敛到局部最小值但不是全局最小值
>           优点：
>               算法简单，容易实现，算法速度快，找到使平方误差函数值最小的k个划分
>           缺点：
>               适合数值型数据
>               可能收敛到局部最小值
>               在大规模数据上收敛较慢
>               对初值敏感，分组的数目k是一个超参数，需要调参
>               对噪声敏感，少量的噪声能对平均值产生极大影响
>
>
>
>
>
>
>
>
>

- **待续：**
>       参考：https://mp.weixin.qq.com/s/zlRAx8PcPi9engcdyNIpNw
>           http://www.cnblogs.com/pinard/p/6069267.html
>
>
>
>
>
>
>
>
>
>
>
>
>
