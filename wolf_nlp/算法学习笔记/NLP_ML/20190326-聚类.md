## NLP_ML - 聚类
- **概述：**
>       常见的聚类可以分为几大类，如，
>           属性划分法:
>               K-MEDOIDS算法
>               CLARANS算法
>           层次法：
>               BIRCH算法
>               CURE算法
>               CHAMELEON算法
>           密度法：
>               DBSCAN算法
>               OPTICS算法
>               DENCLUE算法
>           基于网格方法：
>               STING算法
>               CLIQUE算法
>               WAVE-CLUSTER算法
>
>

- **聚类类型：**
>       1、原型聚类
>           a、K-Means聚类
>               K-Means与高斯混合聚类：
>                   (K-Means算法可看做高斯混合聚类在混合成分方差相等、且每个样本仅指派给一个混合成分时的特例。)
>               K-Means算法针对聚类所得族划分，根据优化最小化平方误差，得到最终结果。
>               要找到最优解需要考察样本集所有可能的族划分，这是一个NP难题。因此k均值算法采用了贪心策略，通过迭代优化近似求解。
>           b、学习向量量化LVQ(Learning Vector Quantization)
>               LVQ假设数据样本带有类别标记，学习过程利用样本的这些监督信息来辅助聚类
>               算法过程：
>                   a1、先用样本随机初始化一组原型向量
>                   a2、使用其他样本更新原型向量，相同类型的则原型向量更靠近样本，否则更加远离样本
>                   a3、训练迭代直到收敛
>           c、高斯混合聚类
>               思想：
>                   使用概率模型来表达聚类原型，族划分是由原型对应后延概率确定
>               对n维样本空间X中的随便向量x，若x服从高斯分布，其概率密度函数(公式略)。其分布由均值向量u和协方差矩阵∑两个参数确定。
>               高斯混合分布：
>                   该分布由k个混合成分组成，每个混合成分对应一个高斯分布，其中ui和∑i是第i个高斯混合成分的参数，而ai为相应的混合系数
>               模型参数计算：
>                   采用极大似然估计，然后采用EM算法进行迭代优化求解。
>       2、密度聚类
>           算法思想：
>               假设聚类结构能通过样本分布的紧密程度确定。通常情况下，密度聚类算法从样本密度的角度来考察样本之间的可连续性，并基于可连续性不断扩展聚类族以获得聚类结果
>           DBSCAN算法：
>               基于一组"邻域"参数来刻画样本分布的紧密程度。
>               族：由密度可达关系导出的最大的密度相连样本集合
>               优点：
>                   a、不需要假设类别数k，可以发现任意形状的聚类族（K-Means仅用于凸数据集），在聚类的同时还可以找出异常点，对数据中的异常点不敏感
>                       如果数据是稠密的，并且不是凸的，用DBSCAN比K-Means效果好
>                       如果数据不是稠密的，不推荐使用DBSCAN
>               缺点：
>                   a、密度不均匀、聚类间距差相差很大，聚类质量较差
>                   b、相对于K-Means，DBSCAN调参较复杂，主要是聚力阈值ϵ、邻域样本数阈值MinPt联合调参
>                       如果MinPts不变，ϵ取得值过大，会导致大多数点都聚到同一个簇中，
>                                  ϵ过小，会导致一个簇的分裂；
>                       如果ϵ不变，MinPts的值取得过大，会导致同一个簇中点被标记为离群点
>                                 MinPts过小，会导致发现大量的核心点
>                   c、不适合高维数据
>                   d、在sklearn中效率很慢
>       3、层次聚类
>           试图在不同层次对数据集进行划分，从而形成树形的聚类结构。数据集的划分可采用"自底向上"的聚合策略，也可采用"自顶向下"的分拆策略
>           AGNES：
>               采用自底向上聚合策略的层次聚类算法
>

- **聚类算法比较：**
>       K-Means VS k-medoids：
>           K-Means通过均值计算中心点
>           k-medoids类似于通过中位数确定中心点，相比K-Means时间复杂度较高
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>

- **待续：**
>       参考：<<机器学习>> 周志华
>           https://www.cnblogs.com/blfshiye/p/4553764.html  从决策树学习谈到贝叶斯分类算法、EM、HMM
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
