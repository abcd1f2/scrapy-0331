## NLP_ML - 模型融合
- **概述：**
>       常见的模型融合：
>           模型组合（ensemble of model）
>           模型堆叠（stacking）
>
>

- **模型融合的结合策略：**
>       1、平均法
>           boosting系列中，采用的是加权平均融合
>       2、投票法
>           在bagging模型中使用
>       3、学习法
>           一种更强大的结合策略是使用"学习法"，即通过另一个学习器来进行结合，把个体学习器称之为初级学习器，用于结合的学习器称为次级学习器或元学习器
>           常用的有Stacking和Blending两种：
>           Stacking：
>               Stacking 先从初始数据集训练出初级学习器，然后”生成”一个新数据集用于训练次级学习器。在这个新数据集中，初级学习器的输出被当作样例输入特征，而初始样本的标记仍被当作样例标记。
>               stacking一般使用交叉验证的方式，初始训练集D 被随机划分为k 个大小相似的集合D1 ， D2 ， … ， Dk，每次用k-1个部分训练T个模型，
>                   对另个一个部分产生T个预测值作为特征，遍历每一折后，也就得到了新的特征集合，标记还是源数据的标记，用新的特征集合训练一个集合模型。
>           Blending：
>               Blending与Stacking大致相同，只是Blending的主要区别在于训练集不是通过K-Fold的CV策略来获得预测值从而生成第二阶段模型的特征，而是建立一个Holdout集，例如说10%的训练数据，
>                   第二阶段的stacker模型就基于第一阶段模型对这10%训练数据的预测值进行拟合。说白了，就是把Stacking流程中的K-Fold CV 改成 HoldOut CV              
>
>
>
>
>
>
>
>
>
>
>
>

- **待续：**
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
