## NLP_ML - 异常值处理
- **概述：**
>       模型通常是对整体样本数据结构的一种表达方式，这种表达方式通常抓住的是整体样本一般性的性质，而那些在这些性质上表现完全与整体样本不一致的点，就称其为异常点
>       从另一方面来说，异常点在某些场景下反而令分析者感到极大兴趣，如：
>           1、疾病预测
>               通常健康人的身体指标在某些维度上是相似，如果一个人的身体指标出现了异常，那么他的身体情况在某些方面肯定发生了改变，
>               当然这种改变并不一定是由疾病引起（通常被称为噪音点），但异常的发生和检测是疾病预测一个重要起始点。
>           2、信用欺诈
>           3、网络攻击
>

- **异常检测常用的方法：**
>       1、简单统计（均值、方差、分位数等）       
>       2、3∂原则（数据需要服从正太分布）
>           在3∂原则下，异常值如超过3倍标准差，那么可以将其视为异常值
>       3、箱型图
>           箱型图的四分位距（IQR）对异常值进行检测
>           规定：超过上四分位+1.5倍IQR距离，或者下四分位-1.5倍IQR距离的点为异常值。
>       4、基于模型检测
>           这种方法一般会构建一个概率分布模型，并计算对象符合该模型的概率，把具有低概率的对象视为异常点。如果模型是簇的集合，则异常是不显著属于任何簇的对象；
>               如果模型是回归时，异常是相对远离预测值的对象。
>           比如特征工程中的RobustScaler方法，在做数据特征值缩放的时候，它会利用数据特征的分位数分布，将数据根据分位数划分为多段，只取中间段来做缩放，
>               比如只取25%分位数到75%分位数的数据做缩放。这样减小了异常数据的影响。
>       5、基于近邻度（KNN）的离群点检测
>           确定数据集的有意义的邻近性度量比确定它的统计分布更容易。这种方法比统计学方法更一般、更容易使用，因为一个对象的离群点得分由到它的k-最近邻（KNN）的距离给定
>           注意：离群点得分对k的取值高度敏感。
>               如果k太小，则少量的邻近离群点可能导致较低的离群点得分；
>               如果K太大，则点数少于k的簇中所有的对象可能都成了离群点。
>               为了使该方案对于k的选取更具有鲁棒性，可以使用k个最近邻的平均距离。
>       6、基于密度的离群点检测
>           从基于密度的观点来说，离群点是在低密度区域中的对象。基于密度的离群点检测与基于邻近度的离群点检测密切相关，因为密度通常用邻近度定义。
>           一种常用的定义密度的方法是，定义密度为到k个最近邻的平均距离的倒数。如果该距离小，则密度高，反之亦然。
>           另一种密度定义是使用DBSCAN聚类算法使用的密度定义，即一个对象周围的密度等于该对象指定距离d内对象的个数。
>       7、专门的离群点检测
>           两个专门用于检测异常点的方法比较常用：
>               a、One Class SVM
>               b、Isolation Forest（孤立森林）
>                   相较于LOF，K-means等传统算法，孤立森林算法对高纬数据有较好的鲁棒性。
>                   iForest算法由于简单高效的特点，常用于网络安全中的攻击检测和流量异常等分析。！！！
>

- **异常值的处理方法：**
>       一般异常值的处理方法可大致分为以下几种：
>           1、删除含有异常值的记录
>               直接将含有异常值的记录删除
>           2、视为缺失值
>               将异常值视为缺失值，利用缺失值处理的方法进行处理
>           3、平均值修正
>               可用观测值的平均值修正该异常值
>           4、不处理
>               直接在具有异常值的数据集上进行数据挖掘
>
>
>
>
>
>
>

- **待续：**
>       参考：
>
>   
>
>   
>
>   
>
>   
>
>   
>
>   
>
>   
>
>   
>
>   
>
>   
>
>   
>
>   
>
>   
