### NLP相关算法-CRF
- **概述：**
>  条件随机场最早用于NLP领域，主要用于文本标注，并可以在分词(标注字的词位信息，由字构词)、词性标注(标注分词的词性，如：名词、动词等)、命名实体识别(识别人名、地名、机构名等实体名词)
>

- **模板：**
> CRF一共有两种模板u-gram和b-gram
>
> **u-gram模板：**
>       u-gram就是unigram template，描述了unigram feature
>       一元模板，表示只与当前位置对应的标签相关的特征
>
> **b-gram模板：**
>       b-gram：就是bigram template
>       二元模板，表示前一个位置和当前位置对应的标签相关的特征
>       注：当类别数很大的时候，这种类型会产生许多可区分的特征，这将会导致训练和测试的效率都很不好
>
>**实例讲解：**
>
>>模板如下：
        # Unigram
        U00:%x[-2,0]
        U01:%x[-1,0]
        U02:%x[0,0]
        U03:%x[1,0]
        U04:%x[2,0]
        U05:%x[-2,0]/%x[-1,0]/%x[0,0]
        U06:%x[-1,0]/%x[0,0]/%x[1,0]
        U07:%x[0,0]/%x[1,0]/%x[2,0]
        U08:%x[-1,0]/%x[0,0]
        U09:%x[0,0]/%x[1,0]
        # Bigram
        B
>
> 每个特征后面的数字用于区分特征，这些数字不是一定要连续
>
>假设我们的训练语料句子是：我是中国人(下表：-2,-1,0,1,2)，我们考虑的当前位置为：中
>
> U00-U04特征模板：表示某个位置与当前位置的信息之间的关系，比如U00，指的是"我"和"中"之间的联系
>
> U05-U07特征模板：表示某三个位置与当前位置的信息之间的关系，比如U05，指的是"我"、"是"、"中"和"中之间的联系"
>
> U08-U09特征模板：表示某两个位置与当前位置的信息之间的关系，比如U08，指的是"是"、"中"和"中"之间的联系
>
> 注：一般使用unigram就足够了，若使用bigram，也使用最简单的模板，它会带来效率低下的问题
>
> 注：比如做词性标注工作的时候，我们知道"动词后边很容易跟名词，所以某个位置的词性与其附近的词性有很大的关系"，所以说这种情况下，动词后边名词的概率会变高，指引我们"动词后边名词的概率很大"
> 


- **特点：**
> <b>CRF VS 词典分词：</b>
>
> 优点：对汉字进行标注即由字构词(组词)，不仅考虑了文字词语出现的频率信息，同时考虑上下文信息，具备较好的学习能力，对歧义词和未登录词识别有良好的效果
>
> 缺点：训练周期长，计算量大，模型较大，性能不够好
>
><b>CRF VS HMM、MEMM：</b>
> CRF、HMM、MEMM(最大熵隐马模型)常用来做序列标注的建模，如分词、词性标注、命名实体
>
> 隐马模型：缺点是其独立性假设，导致其不能考虑上下文的特征，限制了特征的选择
>
> 最大熵隐马模型：可以任意选择特征，解决了隐马模型的问题，但是要在每一个节点都要进行归一化，所以只能找到局部最优值，同时也存在标记偏见的问题，即凡是在语料中未出现的情况全部忽略
>
> 条件随机场模型：不在每一个节点进行归一化，而是搜优特征进行全局归一化，可以求得全局最优解
>
>
>
- **分词原理：**
>1、CRF把分词当做字的词位分类问题，通常定义词位信息为EBMS，
>
>2、分词的过程就是对词位标注，然后进行分词
>
>3、分词实例：
>       原句：原始例句：我爱北京天安门
>       CRF词位标注：我/S 爱/S 北/B 京/E 天/B 安/M 门/E
>       分词结果：我/爱/北京/天安门
>
>
>
>
>



































a
