### NLP相关算法-HMM
- **概述：**
>       参考：http://www.52nlp.cn/hmm%E7%9B%B8%E5%85%B3%E6%96%87%E7%AB%A0%E7%B4%A2%E5%BC%95
>
>

**应用：**
>       Ansj的词性标注是基于HMM的，主要利用了ngram的方式，
>       Ansj分词是一个ictclas的Java版本，基本原理一致，在分词优化算法上做了一些改进。
>
>
>
>       Ansj分词步骤：
>           1、全切分，原子切分
>           2、N最短路径的粗切分，根据隐马模型和viterbi算法，规划最优路径
>           3、人名识别
>           4、系统词典补充
>           5、用户自定义词典补充
>           6、词性标注
>

- **HMM：**
>       HMM是一个通用的算法，可以解决贴标签的一系列问题
>           应用：命名实体识别中，给一个词序列，求出最可能的标签(人名、地名),如ICTCLAS命名实体识别
>                 分词中，给出一个字序列，求最可能的标签序列(BMES)，如jieba分词
>                 词性标注中，当给出一个观察序列(句子)，求出最可能的隐藏状态序列(词性)，如ansj和ICTCLAS分词中
>                 李开复最先提出的使用hmm应用在语音识别
>                 hanlp中使用hmm-viterbi角色标注中国人名三层HMM(有张华平教授的论文)、角色标注地名、角色标注机构名、音译人名和日本人名
>
>       利用HMM角色标注实现了命名实体识别
>       viterbi与HMM的关系：求解最可能的隐状态序列是HMM的三个经典问题之一，通常用viterbi算法解决。viterbi算法是求解HMM上的最短路径的算法
>       三个经典问题：
>           1、概率计算问题 估计问题 评估
>               给定模型参数情况下，求某种观测序列出现的概率
>               应用：比如求一个句子出现的概率
>               算法：暴力计算法，前向、后向算法解决的是一个评估问题，即给定一个模型，求某特定观测序列的概率，用于评估该序列最匹配的模型
>           2、学习问题 参数估计 学习
>               给定观测序列，需要求出HMM的参数问题
>               应用：训练模型参数
>               算法：Baum-Welch算法解决的是一个模型训练问题，即参数估计，是一种无监督的训练方法，主要通过EM迭代实现；即只有观测序列，无状态序列时训练模型
>           3、预测问题 序列问题 解码
>               给定观测序列，也知道HMM参数，求出造成这个观测序列最优可能对对应的状态序列
>               应用：NLP中，词性标注中，当给出一个观察序列(句子)，求出最可能的隐藏状态序列(词性)，如ansj和ICTCLAS分词中
>                    分词中，给出一个字序列，求最可能的标签序列(BMES)，如jieba分词
>                    命名实体识别中，给一个词序列，求出最可能的标签(人名、地名),如ICTCLAS命名实体识别
>               算法：近似算法->贪心算法->局部最优，维特比算法解决的是给定一个模型和某个特定的输出序列，求最可能产生这个输出的状态序列。如通过海藻变化（输出序列）来观测天气（状态序列），是预测问题，通信中的解码问题
>
>
>       应用：
>           1、标注中国人名：
>               <<基于角色标注的中国人名自动识别研究>>论文中描述了算法原理
>               1、通过对构成角色进行标注，通过对角色序列进行模式匹配进行人名识别
>               2、统计标签的出现频次，转移矩阵(转移概率)
>               3、对粗分结果角色标注，模式匹配(ac算法)
>           2、音译人名：
>               欧美和俄罗斯的音译人名：
>                   使用常用字集，然后用触发法，当分词发现有nrf(有一个nrf.txt词典)，然后就把后面的常用字附加到后面
>               日本人名：
>                   因为日本人名中常用字同样是汉语词汇的常用字，所以一般的字法来做日本人名识别效果非常差
>                   依旧是之前的思路，设定触发条件，当分词发现有日语姓氏(日本姓词典)，然后把后面的常用字或常用组合附加到后面
>           3、地名识别：
>               a、对熟语料自动角色标注
>               b、统计单词角色频次、角色转移概率，训练一个模型
>               c、识别 利用hmm-viterbi标注陌生文本的粗分结果，利用ac算法进行模式匹配，匹配出可能的地址，传入到第二层的隐马模型中
>           4、机构名识别：
>               命名识别中最难的属实体机构识别，因为机构名十分复杂，有人名、地名、数字、字号等
>               与人名和地名识别不同的是，命名实体识别前，需要先执行人名和地名识别，然后将粗分结果送入hmm模型中求解，得出细分结果后才能继续进行，因为人名和地名也是机构名的常见成分
>               a、角色标注：
>               b、统计机构名词频：
>               c、统计角色转移矩阵：利用角色转移矩阵和角色词频可以计算出hmm的初始概率、转移概率、发射概率
>               d、模式匹配：使用(ac算法)模式匹配，
>               e、隐马模型细分：第四层隐马模型，第一层粗分，第二层地名识别，第三层细分结果作为这一次的输入，这次细分后得到最终结果
>               总结：多层HMM模型在消耗性能的前提下提高准确度，识别命名实体
>
>
>

- **HMM中的几个算法：**
>       HMM是一个统计模型，总结：一个模型，四大问题，几大算法
>       Filtering（滤波），Smoothing，Evaluation，Decoding四大问题
>           1、Filtering（滤波）
>           2、Smoothing
>           3、Evaluation
>           4、Decoding
>
>       前向算法:给定隐马模型，定义到时刻t为止的观测序列，且状态为qi的概率为前向概率，dp算法
>       后向算法：给定隐马模型，定义在时刻t状态为qi的条件下，到t+1到T的部分观测序列概率为后向概率，dp算法
>
>
>
>
>
>


- **待续**
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
