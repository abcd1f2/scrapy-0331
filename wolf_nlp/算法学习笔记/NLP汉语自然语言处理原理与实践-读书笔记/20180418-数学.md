### NLP汉语自然语言处理原理与实践-数学知识
- **常用概念：**
>       回归：比如在线性回归中，利用一条直线对样本点进行拟合，这个拟合过程就叫做回归
>
>
>
>



- **最小二乘和最大释然：**
> 最大释然估计：从模型中随机抽取n组样本的观测值，最合理的参数估计量应该就是从模型中抽取该n组样本观测值的概率最大
>  最大释然的思想就是什么样的参数才能使我们观察到目前这组数据的概率最大
>
> 最小二乘：得到使得模型能最好地拟合样本数据的参数估计量，就是估计值和观测值之差的平方和最小
>
>
>


- **Sigmoid和softmax总结：**
>       Sigmoid函数：也叫逻辑斯谛函数，logistic
>           逻辑斯蒂函数就是sigmoid函数，几何形状就是一条sigmoid曲线
>           y = 1 / (1 + e^x)
>           hθ(x) = g(θ^T * X)
>                            |x0|
>           z = [θ0,θ1...θn] |x1| = θ^T * X (就是θ向量的转置与X的乘积)
>                            |xn|
>           g(z) = 1 / (1 + e^(-z))
>           最后合并后 hθ(x) = g(θ^T * X) = 1 / (1 + e^(θ^T * X))
>
>       softmax函数：softmax函数
>           y = e^zj / (对e^zk指数求和)
>           当k等于2时，softmax退化为logistic回归，即softmax是logistic回归的一般形式.
>
>       当对k个类型进行分类时，如果k个类别互斥，那么选择softmax回归分类器，如果某一个样本数据属于k个类别中的多种，
>           选择使用logistic回归算法建立k个独立的二元分类器
>

- **待续：**
