### Google算法 - Simhash去重算法
- **概述：**
>       Simhash是Google用来处理海量文本去重的算法，同时也是一种基于LSH(locality sensitive hashing)的算法。和md5算法不同，局部敏感哈希可以将相似的字符串hash得到相似的hash值，
>           使得相似项比不相似项更可能hash到一个桶中，hash到同一个桶中的文档间成为候选对。
>           时间复杂度：可以接近线性的时间去解决相似性判断和去重问题。
>           原理：
>               Simhash通过计算每个特征(关键词)的哈希值，并最终合并成一个特征值即指纹。！！！！！！
>           匹配过程：
>               经过simhash指纹生成算法生成的指纹是一个f位的二进制字符串，如一个32位指纹，'0100101000100100101101110001'。对两个文本的f位01字符串，simhash算法采用hamming distance来计算
>               两个指纹之间的相似度。当面对海量指纹集合时，一个简单的思想就是以空间换时间，对于一个32位指纹来说，将该指纹划分成4段，即4个区间，每个区间8位，如果两个指纹至多存在3(设k=3)位差异，
>               那么至少有一段8位是完全相同的，因此可以考虑利用分段来建立索引，来减少需要匹配的候选指纹的数量。
>           优点：
>               算法效率高，比较适合长文本
>           缺点：
>               同时simhash算法那没有考虑去重的粒度及词的顺序，面对高精度时可能会带来准确度问题
>
>
>

- **使用simhash扩展到海量数据：**
>       如何在海量数据中查询与其海明距离在3位以内的记录呢？
>       方案1：
>           将64位的simhash code的所有3位以内变化的组合，大约需要查询四万多次
>       方案2：
>           预生成样本simhash code的3位变化以内的所有组合，大约需要四万多倍的空间存储
>       方案3：
>           步骤1：将64位的二进制simhash code分成4块，每块16位。根据鸽巢原理（也叫抽屉原理），如果海明距离在3以内，那么它们必有一块完全相同。！！！！！
>           步骤2：然后把分成的4块中的每一块分别作为前16位来进行查找，创建倒排索引
>                 类似于分词后将每个词作为索引创建倒排索引
>
>

- **应用：**
>       simhash从最开始用的最多的场景就是大规模文本的去重，对于爬虫从网上爬取的大规模语料数据，需要进行去重，考虑到计算复杂度和效果，simhash是一种不错的选择。
>       注意：
>           在实际应用过程中，发现一些badcase，完全无关的文本正好应对了相同的simhash，精确度不高，而且simhash更适用于较长的文本，
>           但是在大规模语料进行去重时，simhash的计算速度优势还是很快的。
>
>
>
>
>
>
>
>
>
>
>

- **参考：**
>       https://wizardforcel.gitbooks.io/the-art-of-programming-by-july/content/06.03.html
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
