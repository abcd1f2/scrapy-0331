### 七月在线NLP -- bayes
- **概述：**：
>       ！！！朴素贝叶斯方法=贝叶斯公式 + 条件独立假设
>       ！！！P(y|x) = p(y)P(x|y) / p(x)，其中P(x|y)叫似然函数
>       最大似然法就是求似然函数的最大值
>       朴素贝叶斯：
>           朴素贝叶斯不是假设词之间相互独立，而是假设每一项每一项相互独立
>           条件独立假设
>           当遇到有些项的概率为0的时候，可以使用平滑，但是使用平滑不一定能影响最终的结果，只是一个过渡
>       处理重复词的方法：
>           多项式模型：
>               重复几次计算几次概率
>               当出现重复的时候，会连续计算多次概率，即会出现指数形式，所以叫多项式模型
>           伯努利模型：
>               就是普通的贝叶斯，只关注是否出现
>           混合模型：
>               计算的时候不考虑重复词出现的次数，统计的时候会统计多次计算概率
>           高斯模型：
>               针对连续值的处理
>           一般在数据量比较大时，伯努利和多项式模型差别很小
>       实际工程中遇到的问题：
>           1、概率相乘改为取对数，提前计算log存入到hash表中
>           2、对数的比较大小可以转换成为对数里面的除法
>           3、选取topk的关键词进行计算，忽略低频词（具体选取多大需要经验得出）
>           4、分割样本（比如在垃圾邮件中混入正常内容，垃圾概率会被稀释）
>               比如：5000个词的邮件，每500个词抽取5个关键词，一共抽取50个关键词
>           5、位置权重：
>               比如：在邮件标题中注入垃圾内容或者在第一句中注入垃圾内容
>           6、蜜罐：
>               训练集需要不断更新，注册邮箱发布在各大论坛让别人主动发最近格式的垃圾邮件
>
>       贝叶斯方法常见应用以及实际工程中的常见问题：
>           1、褒贬分析，
>               ticks：1、对否定词的特别处理，即数据预处理
>                      2、情感词一般在文本中只出现一次，这种一般用伯努利模型，可以防止其他的词稀释情感词的作用
>                       对副词对情感的影响，比如不很喜欢和很不喜欢
>                       情绪的含蓄表达和转折表达，比如，导演你出来，保证不打死你。
>           2、拼写纠错
>               参考网上有一篇介绍贝叶斯的paper
>           3、语种分类
>               （sklearn的model_selection的train_test_split方法可以实现训练和测试数据的切分）
>               使用sklearn的多项式贝叶斯
>           4、也可以进行词性标注
>               就是一个词进行多分类的问题（众多词性中选择一种）
>               引入ngram方法提升准确率
>           5、中文分词
>           6、机器翻译和语音识别
>       贝叶斯方法的优化：
>           1、嵌入ngram方法
>               （做翻译的时候做过中文的5元模型）
>               （从3元到5元，翻译的效果会好一些，但是参数太多）
>               ngram的相关问题也必须解决，比如平滑
>               拉普拉斯：比较粗暴，一般效果不好
>               good-turing平滑
>               kenlm语言模型的训练工具，速度比较快，出来的模型已经加入了平滑的处理
>
>
>       
>
>
>       
>
>
>       
>
>
>       
>
>
>       
>
>
>       
>
>
>       
>
>
