### 七月在线NLP -- word2vec
- **概述：**：
>       nlp常见任务：
>           自动摘要
>           指代消解（小明放学了，妈妈去接他  语句中的他指代谁）
>           机器翻译
>           词性标注
>           分词（工程中实际应用的话 hmm应用比较多）
>           主题识别
>           文本分类
>
>       文本特征：
>           词袋模型
>           TF-IDF
>           ngram构造特征
>
>       word2vec：
>           分布式表达
>           用一个词附近的其他词来表示该词。(1957年)
>           现代统计自然语言处理中最有创见的想法之一
>
>           共现矩阵：
>               文本的共现矩阵主要用于发现主题topic，用于主题模型，如LSA
>               局域窗
>               维度过大
>               对共现矩阵用SVD（降维的时间复杂度为n^3）、PCA对主成分进行降维
>
>           word2vec：（13年提出）
>               word2vec会在deep learning上应用很广
>               神经网络希望维度较小，减小计算量
>               NNLM（03年提出 计算量比较大）：neural netword language model
>                   word2vec的前身
>               CBOW：
>                   对输入层进行sum，目标函数就是每个词对当前词的乘积连乘积最大
>           word2vec缺点：
>               1、对多语义无法处理，因为使用了唯一的词向量
>               2、对每个local content单独训练，没有利用包含在global co-currence矩阵中的统计信息
>
>           CBOW和Skip gram工程中选用经验：
>               CBOW：样本量不是很大时使用
>               Skip gram：样本量非常大时采用
>
>       Doc2Vec模型:
>           应用效果并不是很好？
>
>       glove：
>           利用全局信息编码词向量（可以解决一次多义的情况，实际工程中使用不多）
>
>       评估word2vec的好坏：
>           1、词类比任务
>           2、词相似度任务
>           3、评估CRF的实体识别效果
>           word2vec还是应用最广泛的应用
>
>       计算词语的词向量时，可以先进行预处理，比如使用tf-idf取重要的词，过滤掉不重要的词，然后进行计算
>
>       word2vec应用到文本分类或者情感分析的优化方法：
>           1、使用tf-idf取出重要的词语
>           2、对单词进行聚类
>           3、lstm 算法优化
>           word2vec处理句子的缺点：
>               计算句子的词向量时，忽略了单词之间的顺序关系
>
>       word2vec在推荐系统中的应用：
>           用户的浏览路径看做一个句子，每一个点击相当于一个单词，对每个用户的浏览序列进行训练
>           用户行为序列
>
>
>
>       应用：
>           情感分析：
>               Doc2Vec模型有两种方法：DM和DBOW
>               DM：给定上下文和段落向量预测单词的概率
>               DBOW：仅在给定段落向量的情况下预测段落中随机单词的概率
>               在情感分析中，word2vec对词向量进行平均处理，但是忽略了单词之间的排列顺序对情感分析的影响，于是提出了Doc2Vec方法，增加了一个段落向量，其余的和Word2vec相同
>
>               因为在分析段落时，如果忽略上下文和单词顺序的信息，我们将丢失许多重要的信息
>
>
>           应用步骤：
>               训练每个词的词向量
>               句子词向量的获取：
>                   1、句子的词向量为每个词的词向量加和平均
>                   2、对词进行聚类 看哪些词属于一类词 然后可以用中心表示
>
>

- **word2vec在深度学习中的应用：**
>       文本生成 文本预测：
>
>
>
>
>
>
>

- **fasttext的应用：**
>       在word2vec基础上，通过模型用途（文本分类）+ 空间（hash） + 时间（haff树） 提速，实现了fasttext
>       调参：
>           交叉验证
>           网格搜索
>
>       gensim构建词向量步骤：
>           1、model= Word2Vec()  建立一个空的模型对象
>           2、model.build_vocab(sentences)  遍历一次语料库建立词典
>           3、model.train(sentences，total_examples = model.corpus_count，epochs = model.iter)  第二次遍历语料库建立神经网络模型
>           4、print(model['man'])  获取词向量
>           5、model.most_similar(['男人']) 计算一个词的最近似的词，倒排序
>           6、model.most_similar(positive = ['woman','king'],negative = ['man'],topn = 2)  支持词语的加减运算
>           7、model.similarity('女人', '男人')  计算两词之间的相似度
>           8、list_sim1 = model.n_similarity（list1，list2） 计算两个集合之间的余弦似度
>           9、model.doesnt_match('breakfast cereal dinner lunch'.split()) 选出集合中不同类的词语
>
>
>
>
>
>
>
>
>
>
>
>


- **待续：**
>
>
>
>
>
>
>
>
>
