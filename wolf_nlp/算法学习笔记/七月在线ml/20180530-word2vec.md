### 七月在线NLP -- word2vec
- **概述：**：
>       nlp常见任务：
>           自动摘要
>           指代消解（小明放学了，妈妈去接他  语句中的他指代谁）
>           机器翻译
>           词性标注
>           分词（工程中实际应用的话 hmm应用比较多）
>           主题识别
>           文本分类
>
>       文本特征：
>           词袋模型
>           TF-IDF
>           ngram构造特征
>
>       word2vec：
>           分布式表达
>           用一个词附近的其他词来表示该词。(1957年)
>           现代统计自然语言处理中最有创见的想法之一
>
>           共现矩阵：
>               文本的共现矩阵主要用于发现主题topic，用于主题模型，如LSA
>               局域窗
>               维度过大
>               对共现矩阵用SVD（降维的时间复杂度为n^3）、PCA对主成分进行降维
>
>           word2vec：（13年提出）
>               word2vec会在deep learning上应用很广
>               神经网络希望维度较小，减小计算量
>               NNLM（03年提出 计算量比较大）：neural netword language model
>                   word2vec的前身
>               CBOW：
>                   对输入层进行sum，目标函数就是每个词对当前词的乘积连乘积最大
>           word2vec缺点：
>               1、对多语义无法处理，因为使用了唯一的词向量
>               2、对每个local content单独训练，没有利用包含在global co-currence矩阵中的统计信息
>
>           CBOW和Skip gram：
>               CBOW：样本量不是很大时使用
>               Skip gram：样本量非常大时采用
>
>       glove：
>           利用全局信息编码词向量（可以解决一次多义的情况，实际工程中使用不多）
>
>       评估word2vec的好坏：
>           1、词类比任务
>           2、词相似度任务
>           3、评估CRF的实体识别效果
>
>
>       应用：
>           情感分析：
>               Doc2Vec模型有两种方法：DM和DBOW
>               DM：给定上下文和段落向量预测单词的概率
>               DBOW：仅在给定段落向量的情况下预测段落中随机单词的概率
>               在情感分析中，word2vec对词向量进行平均处理，但是忽略了单词之间的排列顺序对情感分析的影响，于是提出了Doc2Vec方法，增加了一个段落向量，其余的和Word2vec相同
>
>               因为在分析段落时，如果忽略上下文和单词顺序的信息，我们将丢失许多重要的信息
>
>
>
>
>
>
>



















- **待续：**
>
>
>
>
>
>
>
>
>
